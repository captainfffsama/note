---
title: "零推导理解Diffusion和Flow Matching"
source: "https://zhuanlan.zhihu.com/p/11228697012"
author:
  - "[[知乎专栏]]"
published:
created: 2025-04-09
description: "一、前言相信点进来看这篇文章的读者都对这两个算法有所耳闻，它们正是如今大红大紫的AI生成图像、生成视频所使用的方法。而且很多人可能跟我一样，接触初期也曾尝试过去阅读、理解、推导它们的公式，比如看苏神的…"
tags:
  - "clippings"
---
## 一、前言

相信点进来看这篇文章的读者都对这两个算法有所耳闻，它们正是如今大红大紫的AI生成图像、生成视频所使用的方法。而且很多人可能跟我一样，接触初期也曾尝试过去阅读、理解、推导它们的公式，比如看苏神的生成扩散模型系列（ [生成扩散模型漫谈（一）：DDPM = 拆楼 + 建楼](https://link.zhihu.com/?target=https%3A//kexue.fm/archives/9119) ），结果读着读着就从入门到放弃了...

这主要是因为这俩算法的公式实在太多了，对习惯了看一个流程图就了解一篇论文的CVer来说实在是太困难。本文为了照顾懒散惯了的CVer，我决定除了最终loss，不写一个多余的公式，争取做到零推导还能帮助大家建立对这两个算法的直观印象，破除大家的恐惧，下面我们开始。

## 二、DDPM与DDIM

这两个也就是最常见的Diffusion的算法了，一个用于训练，一个用于测试。

其中DDPM的公式相信大家也看过不少次了，下面贴出来：

$xt=αtx0+βtϵ,βt=1−αt,x_t=\sqrt{\alpha_t}x_0+\sqrt{\beta_t}\epsilon, \\ \beta_t=1-\alpha_t,x_t=\sqrt{\alpha_t}x_0+\sqrt{\beta_t}\epsilon, \\ \beta_t=1-\alpha_t,$

其中 $x0x_0x_0$ 是原始图像， $ϵ\epsilon$ 是随机噪声， $αt\alpha_t$ 和 $βt\beta_t$ 是根据采样器采出来的一组数字， $xtx_t$ 是加噪后的图像，也就是网络的输入。网络的输出也很简单，就是噪声 $ϵ\epsilon$ 。

这公式是什么意思呢？口述不太好讲，直接上图：

Diffusion训练过程

这里把 $x0x_0x_0$ 和 $ϵ\epsilon$ 画成正交的了，其实在高维空间中随机采一个噪声，几乎就是会与另一个向量正交的，所以这么画没什么毛病。注意到 $αt2+βt2=1\sqrt{\alpha_t}^2 + \sqrt{\beta_t}^2=1$ ，这就是个圆形公式，所以 $xtx_t$ 恰好就是在上图的圆弧上进行采样的。这里可能有人会说那 $x0x_0$ 和 $ϵ\epsilon$ 不一样长怎么办啊？其实也就是正圆变椭圆而已，并不影响后面的结论。

所以总结一下：DDPM的训练过程，就是从圆弧上采样一个 $xtx_tx_t$ ，带上 $tt$ 这个参数，经过一个很大的网络，预测噪声 $ϵ\epsilon$ （也就是横轴），就这么简单。

说完训练我们再来说说测试，测试的时候大家都知道的，随机生成一个噪声，然后一步一步去噪最终得到 $x0x_0x_0$ ，怎么去噪呢？最直观的理解当然就是怎么加的噪声就怎么去除，加噪时我们是沿弧线采样，那反过头来去噪也应该是沿弧线走。这里原始的DDPM要走高达1000步，并没有人真的把网络推理1000次，而是用DDIM加速这个过程，自己定义走多少步：

DDIM沿弧线从噪声恢复原图

那这其中每一步是怎么走的呢？这里我们也是省去所有推导，直接上DDIM公式（确定性版本，令方差为0）：

$xt−1=αt−1(xt−βtϵtαt)+βt−1ϵt,x_{t-1}=\sqrt{\alpha_{t-1}}(\frac{x_t-\sqrt{\beta_t}\epsilon_t}{\sqrt{\alpha_t}})+\sqrt{\beta_{t-1}}\epsilon_t,x_{t-1}=\sqrt{\alpha_{t-1}}(\frac{x_t-\sqrt{\beta_t}\epsilon_t}{\sqrt{\alpha_t}})+\sqrt{\beta_{t-1}}\epsilon_t,$

这里大部分符号都跟上边一样，但注意到这里的 $ϵ\epsilon\epsilon$ 变成了 $ϵt\epsilon_t$ ，它代表在t时刻网络预测出来的那个 $ϵ\epsilon$ ，不是加噪的时候加的那个噪声了。

这个公式是什么意思呢？同样我们也画一个图：

DDIM推理过程

这一步我们的目标是从 $x_tx_t$ 走到 $x_{t-1}$ ，本身 $x_{t-1}$ 是有表达式的，但因为此时 $x_0$ 是未知的不能用，所以我们得绕一圈。首先我们获得红色虚箭头的表达式： $x_t-\sqrt{\beta_t}\epsilon_t$ ，然后注意到绿箭头与红箭头长度之比为 $\sqrt{\alpha_{t-1}}:\sqrt{\alpha_t}$ ，所以绿色虚箭头的表达式为： $\frac{\sqrt{\alpha_{t-1}}}{\sqrt{\alpha_t}}(x_t-\sqrt{\beta_t}\epsilon_t)$ ，这恰好与DDIM公式的第一项相同，它代表纵轴坐标。而横坐标轴 $\sqrt{\beta_{t-1}}\epsilon$ 本身就不包含 $x_0$ ，所以可以直接用，两项加在一起就跟上边DDIM 的 $x_{t-1}$ 公式一模一样了，是不是非常清晰直观呢？其实并没有什么弯弯绕绕，把图画出来，本来需要大篇幅推导的DDIM公式就被我们轻松得到了。

## 三、Flow Matching

我们趁热打铁，顺便把Flow Matching也讲了，首先上公式：

$x_t = tx_1+(1-t)x_0,x_t = tx_1+(1-t)x_0,$

注意这里换符号了， $x_1x_1$ 代表真实图像，而 $x_0$ 代表噪声，不要跟上边DDPM混了。这个公式就非常简单了，就是一个线性插值：

Flow Matching训练过程

这里不再像DDPM一样是走圆弧，改走直线了。回归目标也有所不同，不再是回归噪声，而是 $v = x_1 - x_0v = x_1 - x_0$ ，其实就是图上那根斜线，也非常直观。

至于Inference过程，因为不再走圆弧改走斜线，公式也简单得令人发指：

$x_{t+1} = x_{t} + \Delta_t v_t,x_{t+1} = x_{t} + \Delta_t v_t,$

其实都不用解释， $\Delta_t\Delta_t$ 就是两个时间间隔，乘上预测的 $v_t$ 就是要走多远。画图也特别简单，我都懒得多画辅助线了：

Flow Matching推理过程

可以看到，Flow Matching比DDPM和DDIM容易理解得多也直观得多，但本质上没有太大差别，走圆弧与走直线的差别可能就跟 $L2L2$ loss和 $L1$ loss差不多，都是类似的目的，效果上也不会有什么太大差别。现在大家都说Flow Matching效果好，但也说不出什么所以然，大概就是人看起来简单，网络学起来也能简单一些吧。（走直线是不是能少走几步？）

## 四、后记

本文在没有用一个公式推导的情况下，通过小学二年级水平的平面几何介绍了Diffusion和Flow Matching两大算法。希望能给对公式有恐惧的同学一些帮助，有了这些直观印象，相信再回过头去推导公式也会更加轻松。

转载请向我私信申请，转载时请带上我的名字。

[所属专栏 · 2024-12-07 01:22 更新](https://zhuanlan.zhihu.com/c_1058780590651871232) [![](https://picx.zhimg.com/v2-f111d7ee1c41944859e975a712c0883b_720w.jpg?source=172ae18b) happynear技术博客王峰 深度学习（Deep Learning）话题下的优秀答主14 篇内容 · 9828 赞同](https://zhuanlan.zhihu.com/c_1058780590651871232) [最热内容 ·从最优化的角度看待Softmax损失函数](https://zhuanlan.zhihu.com/c_1058780590651871232) 编辑于 2024-12-12 10:24・IP 属地北京 [AIGC](https://www.zhihu.com/topic/26215901) [Diffusion](https://www.zhihu.com/topic/26640754)