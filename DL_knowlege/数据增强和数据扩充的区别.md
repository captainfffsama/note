通常来说，自监督学习需要使用较强的数据增强（如裁切、掩码等）来学习的数据表示。为了区分，本文将生成数据视为数据扩充（Data Inflation），二者的区别是，数据扩充是扩大原始数据集的大小，而数据增广是对每个原始样本，在训练过程中进行随机增强。
<[ICLR 2024 | 鸡生蛋蛋生鸡？再论生成数据能否帮助模型训练](https://mp.weixin.qq.com/s/MSSzIl3KnvRzgWVN0ZyW6A)>
>来自 ICLR 2024 Do Generated Data Always Help Contrastive Learning 中文章解释。