[toc]

# 提示设计策略

以下内容来自 [提示设计策略  |  Gemini API  |  Google AI for Developers](https://ai.google.dev/gemini-api/docs/prompting-strategies?hl=zh-cn)

提示设计是指创建提示（即自然语言请求）的过程，这些提示将用来从语言模型获得准确优质的回答。

本页面介绍了一些基本概念、策略和最佳实践，可帮助您开始设计提示，以便充分利用 Gemini AI 模型。

> **注意** ：提示工程是迭代的。这些指南和模板只是起点。根据您的具体使用情形和观察到的模型回答进行实验和改进。
## 针对特定主题的提示指南

想要了解更具体的提示策略？不妨查看我们的其他提示指南，了解以下内容：

- [使用媒体文件进行提示](https://ai.google.dev/gemini-api/docs/files?hl=zh-cn#prompt-guide)
- 使用 [Imagen](https://ai.google.dev/gemini-api/docs/imagen?hl=zh-cn#imagen-prompt-guide) 和 [Gemini 原生图片生成](https://ai.google.dev/gemini-api/docs/image-generation?hl=zh-cn#prompt-guide) 功能生成图片的提示
- [视频生成提示](https://ai.google.dev/gemini-api/docs/video?hl=zh-cn#prompt-guide)

您可以在 [提示库](https://ai.google.dev/gemini-api/prompts?hl=zh-cn) 中找到其他示例提示，这些提示旨在以互动方式展示本指南中分享的许多概念。

## 清晰具体的说明

自定义模型行为的一种有效且高效的方法是向模型提供清晰具体的指令。指令可以采用问题、分步任务的形式，也可以很复杂，例如反映用户的体验和思维模式。

### 输入

输入是提示中您希望模型为其提供回答的必需文本。输入可以是模型回答的问题（问题输入）、模型执行的任务（任务输入）、模型操作的实体（实体输入），或模型完成或继续的部分输入（补全输入）。

| **输入类型** | **提示**                                | **生成的输出**                                                                                                                    |
| -------- | ------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------- |
| Question | 为一家专门销售干花束的花店起个什么名字好？请列出 5 个选项，只需名字。  | 以下是 5 个专门经营干花的花店的名称：<br>1. 永恒之花<br>2. 干燥与愉悦<br>3. 花瓣保护区<br>4. 野花的低语<br>5. 永恒之花                                               |
| 任务       | 请给我一个简单的清单，列出我必须带上露营旅行的物品。清单上应该有 5 项。 | 1. **帐篷：** 防御恶劣天气的避难所。<br>2. **睡袋：** 保持温暖舒适。<br>3. **睡垫：** 为良好睡眠提供隔热和缓冲。<br>4. **头灯或手电筒：** 供夜间活动照明。<br>5. **急救包：** 准备应对小伤小病。 |
| 实体       | 将以下物品分类为\[大，小\]： <br>大象 <br>老鼠 <br>蜗牛             | 以下是分类： <br>**大象：** 大  <br>**老鼠：** 小 <br>**蜗牛：** 小                                                                                        |

#### 部分输入内容补全 

​  
生成式语言模型的工作方式类似于高级自动补全工具。当您提供部分内容时，模型可以提供剩余的内容或者它认为是该内容的延续内容来作为回答。如果您添加了任何示例或上下文，模型可以参考这些示例或上下文。  
​  
以下示例提供了包含指令和实体输入的提示：  
​  
**提示：**

```text
对于给定的订单，返回一个 JSON 对象，其中包含 cheeseburger、hamburger、fries 或 drink 字段，其值是数量。 
订单：一个汉堡和一杯饮料。
```

**回答：** 

```text
{
"cheeseburger": 0,
"hamburger": 1,
"fries": 0,
"drink": 1
}
```

虽然模型按照提示提供了回答，但以自然语言编写指令有时可能并不容易，并且模型需要解释许多内容。 例如，餐馆菜单可能包含许多菜品。为了减小 JSON 回答的大小，建议您省略没有点的菜品。在这种情况下，您可以提供一个示例和 [回答前缀](#prefixes)，让模型来补全它：  
​  
**提示：** 

```text
有效的字段有芝士汉堡、汉堡、薯条和饮料。
订单：给我一个芝士汉堡和薯条 
输出： 
 \`\`\` 
 { 
 "cheeseburger": 1, 
 "fries": 1 
 } 
 \`\`\` 
订单：我想点两个汉堡，一杯饮料和薯条。 
输出：
```

**回答：**

```text
{
"hamburger": 2,
"drink": 1,
"fries": 1
}
```

可以看到，输出中排除了“芝士汉堡”，因为点餐中没有芝士汉堡。  
​  

### 限制条件  

指定有关读取提示或生成回答的任何限制条件。您可以告诉模型要做什么和不应该做什么。例如，您可以在提示中指定一个限制条件，以限制摘要长度：  
​  
**提示：**   

```text
**用一句话总结这篇文本：**
Text: 量子计算机利用量子力学现象，以比任何现代传统计算机都要快得多的指数速度进行计算。在非常微小的尺度上，物质既表现为粒子也表现为波，量子计算利用专用硬件来利用这种行为。量子设备的运行原理超出了经典物理学的范畴。当大规模部署时，量子计算机可用于广泛的领域，如：在网络安全中破解现有的加密方法，同时帮助研究人员创造新的加密方法，在气象学中开发更好的天气预报等。然而，目前最先进的量子计算机仍然主要处于实验阶段，不切实际。
```

​  
**回答：**   

```text
利用量子力学现象，量子计算机可以比传统计算机进行指数级更快的计算，适用于网络安全和气象学等潜在应用，尽管它们目前主要是实验性的且不切实际。
```

### 回答格式  

​  
您可以提供指定回答格式的说明。例如，您可以要求将回答格式设置为表格、项目符号列表、电梯间推销、关键字、句子或段落。以下系统指令会告知模型在回答时更具对话性：  

​  
**系统指令** 

```text
所有问题都应该详细全面地回答，除非用户特别要求简洁的回答。
```

**提示** 

```text
在 2025 年，有什么聪明的方法来经营一家卖 DVD 的生意？
```

**回答：** 

```text
在 2025 年开始销售 DVD 的生意面临着巨大的挑战，因为数字流媒体和点播服务的压倒性主导地位；因此，一种“智能”的方法需要高度专业化的细分市场，一个超越光碟本身的价值主张，以及可能专注于社区或收藏者市场而不是主流消费。以下是 2025 年一家智能 DVD 生意的可能组成部分： 
1. 极端细分市场专业化：你无法与流媒体库竞争。你的业务必须专注于数字不提供或难以提供的领域。这可能包括： 
* 停产和稀有标题：寻找从未以数字形式发布或目前在主要流媒体平台上不可用的电影或电视剧。
    …. (gemini-2.5-flash)  
```

​  

#### 使用补全策略设置回答格式  

​  
[补全策略](#completion) 也有助于设置回答的格式。 以下示例提示模型创建论文大纲：  
​  
**提示：** 

```text
为关于蜂鸟的论文创建一个提纲。
```

**回答：** 

```text
以下是一篇关于蜂鸟的论文的可能提纲： 
I. 引言 
A. 吸引点：以一个关于蜂鸟的引人入胜的事实或描述开始（例如，它们的速度、彩虹般的光泽或微小的体型）。 
B. 背景：简要介绍蜂鸟——它们在哪里被发现（美洲），它们作为独特鸟类的声誉。 
C. 论点陈述：阐述论文的主要观点，这可能是关于蜂鸟的非凡适应、行为和生态重要性的。
..... (gemini-2.5-flash)

```

提示没有指定大纲的格式，模型为您选择了格式。如需使模型以特定格式返回大纲，您可以添加表示大纲开头的文本，并让模型根据您起头的模式补全大纲。  
​  
**提示：** 

```text
为关于蜂鸟的论文创建一个提纲。 
I. 引言
*
```

**回答：** 

```text
好的，以下是关于蜂鸟的论文提纲，从你提供的引言开始：

I. 引言
* 吸引点：从一个引人入胜的事实或描述开始，例如蜂鸟的速度、彩虹般绚丽的颜色或它们微小的体型。
* 背景：简要介绍蜂鸟——它们分布在哪里（美洲）、作为独特鸟类的声誉以及它们的一般特征。
* 论点陈述：阐述论文的主要观点，聚焦于蜂鸟非凡的适应性、行为和生态意义。
...... (gemini-2.5-flash)  
```

## 零样本提示与少样本提示  

您可以在提示中添加示例，以向模型示范想要的结果。模型会尝试识别示例中的模式和关系，并在生成回答时应用它们。包含少量示例的提示称为少样本提示，而不提供示例的提示称为零样本提示。少样本提示通常用于规定模型回答的格式、措辞、范围界定或一般模式。使用具体而多样的示例来帮助模型缩小其重点并生成更准确的结果。  
​  
我们建议始终在提示中包含少样本示例。不含少样本示例的提示可能效果不大。事实上，如果您的示例足够清晰地显示当前任务，则您可以从提示中移除指令。  
​  
以下零样本提示要求模型选择最佳解释。  
​  
**提示：** 

```text
请选择对这个问题的最佳解释： 
问题：雪是如何形成的？ 
解释 1：当空气中的水蒸气在大气中冻结成冰晶时，雪就形成了，这些冰晶可以结合并生长成雪花，当它们穿过大气层并积累在地面上。 
解释 2：水蒸气冻结成冰晶形成雪。 
答案：
```

**回答：** 

```text
解释 1 是更好的解释，因为它提供了关于过程的更多细节，包括冰晶如何在下降穿过大气层的过程中结合并生长成雪花。
…(gemini-2.5-flash)  
```

如果您的用例要求模型生成简洁的回答，您可以在提示中添加偏好简洁回答的示例。  
​  
以下提示提供了两个偏好较短解释的示例。在回答中，您可以看到这些示例引导模型选择较短的解释 (`Explanation2`)，而不是像之前那样较长的解释 (`Explanation1`)。  

**提示：** 

```text
以下是一些展示问题、解释和答案格式的示例：

问题：为什么天空是蓝色的？ 
解释 1：天空之所以呈现蓝色，是因为瑞利散射，这导致较短波长的蓝色光比较长波长的红色光更容易被散射，从而使天空看起来是蓝色的。 
解释 2：由于瑞利散射效应。 
答案：解释 2 

问题：地震的成因是什么？ 
解释 1：地壳中能量的突然释放。 
解释 2：地震发生时，构造板块突然滑动或断裂，导致能量的释放，产生可以震动地面并造成破坏的地震波。 
答案：解释 1

现在，根据上述示例格式回答以下问题：
问题：雪是如何形成的？
解释 1：当空气中的水蒸气在大气中冻结成冰晶时，雪就形成了。这些冰晶可以结合并生长成雪花，当它们穿过大气层并积累在地面上时。
解释 2：水蒸气冻结成冰晶形成雪。
答案：
```

**回答：** 

```text
回答：解释 2
…(gemini-2.5-flash)
```

### 最佳示例数量  

Gemini 等模型通常可以通过少量示例来学习模式，但您可能需要进行多次实验，以找到可产生最佳结果的提示中提供的示例数量。但是，如果您添加太多示例，模型的回答可能会与示例 [过拟合](https://developers.google.com/machine-learning/glossary?hl=zh-cn#overfitting)。  

### 模式与反模式  

使用示例向模型展示要遵循的模式比使用示例向模型展示要避免的反模式更有效。  

⛔ **反模式**：  
​  
**示例**

```text
不要以问题结束俳句：
俳句很有趣 
一首简短的诗
你不觉得有趣吗？
```

✅ **正模式**：  
​  
**示例**

```text
总是以一个断言结束俳句： 
俳句很有趣 
一首简短简单的诗 
写作的乐趣
```

### 采用风格一致的内容形式  

确保少样本示例的结构和格式相同，以避免回答具有不需要的格式。在提示中添加少样本示例的主要目标之一是向模型展示回答格式。因此，必须确保在所有示例中使用一致的格式，尤其是注意 XML 标记、空格、换行符和示例分隔符。  

## 添加上下文  

您可以在提示中添加模型解决问题所需的指令和信息，而不是假设模型具备所有必要信息。这些上下文信息可帮助模型了解您要求其执行的操作的限制和详细信息。  
​  
以下示例要求模型提供路由器的问题排查指导：  
​  
**提示：** 

```text
我应该怎么做才能修复我的断开连接的 wifi？**我 Google Wifi 路由器上的灯是黄色的，并且缓慢闪烁。**
```

**回答：** 

```text
您的 Google Wifi 路由器上闪烁的黄色灯光通常表示互联网连接存在问题。以下是一些故障排除和解决问题的步骤： 
1. 重启您的路由器和调制解调器：
- 将调制解调器从电源插座拔下，等待 30 秒。 
- 将调制解调器重新插回电源插座，等待其完全启动。 
- 将 Google Wifi 路由器从电源插座拔下，等待 30 秒。 
- 将 Google Wifi 路由器重新插回电源插座，等待其完全启动。 
......(gemini-2.5-flash)
```

这个回答看起来是通用的问题排查信息，并非特定于路由器或 LED 指示灯的状态。  
​  
如需针对特定路由器自定义回答，您可以在提示中添加该路由器的问题排查指南作为上下文，供模型在回答时参考。  
​  
**提示：** 

```text
使用下面的文本回答问题。仅回答提供的文本。问题：我应该如何修复断开的 wifi？我的 Google Wifi 路由器上的灯是黄色的，并且缓慢闪烁。

文本： 
颜色：缓慢闪烁的黄色 
含义：存在网络错误。 
操作指南： 检查以太网线是否连接到您的路由器和调制解调器，并且两个设备都已开启。您可能需要重新插拔每个设备。

颜色：快速闪烁的黄色
含义：您正在按住重置按钮，正在对设备进行出厂重置。
操作指南：如果您继续按住重置按钮，大约 12 秒后，灯将变为稳定的黄色。一旦变为稳定黄色，请释放出厂重置按钮。

颜色：稳定的黄色
含义：路由器正在出厂重置。
操作指南：这可能需要长达 10 分钟。完成时，设备将自动重置并开始闪烁白色，表示它已准备好设置。

颜色：稳定的红色
含义：出了问题。
操作指南：严重故障。对路由器进行出厂重置。如果灯保持红色，请联系 WiFi 客户支持。
```

**回答：**

```text
检查以太网线是否连接到您的路由器和调制解调器，并且两个设备都已开启。您可能需要再次拔掉并重新插上每个设备。
......(gemini-2.5-flash)
```

## 添加前缀  

前缀是您添加到提示内容中的字词或短语，有多种用途，具体取决于前缀的位置：  

*   **输入前缀**：为输入添加前缀可向模型指示输入中在语义上有意义的部分。例如，前缀“英语：”和“法语：”区分两种不同的语言。  
*   **输出前缀**：虽然输出由模型生成，您也可以在提示中为输出添加前缀。输出前缀可为模型提供有关预期回答的信息。例如，输出前缀“JSON：”告诉模型输出应采用 JSON 格式。  
*   **示例前缀**：在少样本提示中，为示例添加前缀提供了模型在生成输出时可以使用的标签，使解析输出内容变得更加容易。  
​  
在以下示例中，“文本：”是输入前缀，“答案是：”是输出前缀。  
​  
**提示：**

```text
将文本分类为以下类别之一。 
- 大型 
- 小型
文本：犀牛 
答案是：大型 
文本：老鼠 
答案是：小型 
文本：蜗牛 
答案是：小型 
文本：大象 
答案是：
```

**回答：**

```text
答案是：大型
```

## 将提示分解为各个组成部分  

对于需要复杂提示的用例，您可以将内容细分为更简单的组成部分，以帮助模型管理这种复杂情况。  

1.  **细分指令**：不要在一个提示中包含多条指令，而要为每条指令创建一个提示。您可以根据用户的输入选择要处理的提示。  
2.  **串联提示**：对于涉及多个连续步骤的复杂任务，请将每个步骤设为一个提示，并将这些提示按顺序串联在一起。在这一连串的提示中，序列中一个提示的输出将成为下一个提示的输入。序列中最后一个提示的输出将是最终输出。  
3.  **汇总回答**：汇总是指对数据的不同部分执行不同的并行任务，并汇总结果以生成最终输出。例如，您可以指示模型对数据的第一部分执行一项操作，对其余数据执行另一项操作并汇总结果。  
      
​  
## 对模型参数进行实验  

您向模型发送的每次调用都包含控制模型如何生成回答的参数值。对于不同的参数值，模型会生成不同的结果。因此请尝试不同的参数值，以获得任务的最佳值。不同模型的可用参数可能有所不同。最常见的参数如下：  

1.  **输出词元数上限**：指定回答中可生成的词元数量上限。词元约为 4 个字符。100 个 token 大约对应 60-80 个单词。  
2.  **温度**：温度可以控制 token 选择的随机性。温度 (temperature) 在生成回答期间用于采样，在应用 `topP` 和 `topK` 时会生成回答。较低的温度有利于需要更具确定性或更少开放性回答的提示，而较高的温度可以带来更具多样性或创造性的结果。温度为 0 表示确定性，即始终选择概率最高的回答。  
>注意： 使用 Gemini 3 模型时，我们强烈建议将 temperature 保留为默认值 1.0。更改温度（将其设置为低于 1.0）可能会导致意外行为（例如循环或性能下降），尤其是在复杂的数学或推理任务中。
3.  **`topK`**：`topK` 参数可更改模型选择输出 token 的方式。如果 `topK` 设为 1，表示所选 token 是模型词汇表的所有 token 中概率最高的 token（也称为贪心解码）。如果 `topK` 设为 3，则表示系统将从 3 个概率最高的 token（通过温度确定）中选择下一个 token。在每个词元选择步骤中，系统都会对概率最高的 `topK` 个词元进行采样。然后，系统会根据 `topP` 进一步过滤词元，并使用温度采样选择最终的词元。  
4.  **`topP`**：`topP` 参数可更改模型选择输出 token 的方式。系统会按照概率从最高到最低的顺序选择 token，直到所选 token 的概率总和等于 `topP` 值。例如，如果词元 A、B 和 C 的概率分别为 0.3、0.2 和 0.1，并且 `topP` 值为 0.5，则模型将选择 A 或 B 作为下一个词元（通过温度确定），并会排除 C 作为候选词元。默认 `topP` 值为 0.95。  
5.  **`stop_sequences`**：设置停止序列，告知模型停止生成内容。停止序列可以是任意字符序列。尽量避免使用可能会出现在生成内容中的字符序列。  
      
## 提示迭代策略  

提示设计有时需要进行几次迭代，然后才能稳定获得所需的回答。本部分提供了有关在迭代提示时可以尝试的做法的指导：  

### 1.  使用不同的措辞：

即使含义相同，在提示中使用不同的字词或措辞通常也会使模型生成不同的回答。如果您的提示无法产生预期结果，请尝试重新措辞。  

```text
版本1：
我该如何烤制派？

版本2：
建议一个派的做法。

版本3：
有什么好的派食谱？
```

### 2. 改用类似任务：

如果您无法让模型遵循您的任务指令，请尝试为其提供可实现相同结果的类似任务的指令。  
此提示指示模型使用预定义的类别对一本书进行分类：  
      
**提示：** 

```text
《奥德赛》属于哪个类别：
惊悚片
科幻
神话
传记
```

**回答：**  

```text
《奥德赛》属于神话类别。

以下是原因：

* **神话：** 《奥德赛》讲述了希腊神话中的英雄奥德修斯在特洛伊战争后回家的故事。它包含了希腊神话中常见的神、怪物和超自然事件。
```

回答正确，但模型超出了选项的范围。您还希望模型仅使用其中一个选项（而不是完整的句子）来回答。在这种情况下，您可以将指令改为单选题，并要求模型选择一个选项。  
      
**提示：** 

```text

多项选择题：以下哪个选项描述了《奥德赛》这本书？选项：
惊悚小说
科幻小说
神话
传记    
```

**回答：** 

```text
正确答案是神话。
```

### 3.  更改提示内容的顺序：

提示中内容的顺序有时会影响回答。请尝试更改内容顺序，看看对回答有何影响。  

```text
版本 1：
[示例]
[上下文]
[输入]

版本 2：
[输入]
[示例]
[上下文]

版本 3：
[示例]
[输入]
[上下文]
```

## 后备响应

后备回答是当提示或回答触发安全过滤条件时模型返回的回答。后备回答的一个示例是“我无法提供帮助，因为我只是一个语言模型”。

如果模型给出后备回答，请尝试提高温度。

## 需要避免的事项

- 避免依赖模型来生成事实信息。
    
- 对于数学和逻辑问题请谨慎使用。
    

## Gemini 3

Gemini 3 模型专为高级推理和指令遵从而设计。 它们最能理解直接、结构合理且明确定义了任务和任何限制条件的提示。建议采用以下做法，以充分发挥 Gemini 3 的性能：

### 核心提示原则

- **用词要准确、直接**：清晰简洁地说明您的目标。避免使用不必要或过于具有说服力的语言。
    
- **使用一致的结构**：使用清晰的分隔符分隔提示的不同部分。XML 样式标记（例如 `<context>`、`<task>`）或 Markdown 标题。选择一种格式，并在单个提示中始终使用该格式。
    
- **定义参数**：明确说明任何模棱两可的术语或参数。
    
- **控制输出详细程度**：默认情况下，Gemini 3 会提供直接而高效的回答。如果您需要更口语化或更详细的回答，必须在指令中明确提出要求。
    
- **连贯地处理多模态输入**：使用文本、图片、音频或视频时，将它们视为同类输入。确保您的说明根据需要清晰地提及每种模态。
    
- **优先处理关键指令**：将必要的行为限制、角色定义（角色设定）和输出格式要求放在系统指令中或用户提示的最开头。
    
- **长上下文的结构**：提供大量上下文（例如文档、代码）时，请先提供所有上下文。将具体说明或问题放在提示的 _ 末尾 _。
    
- **锚定上下文**：在提供大量数据后，使用清晰的过渡短语来连接上下文和您的查询，例如“根据上述信息…”
    

### Gemini 3 Flash 策略

- **当前日期准确性**：在开发者说明中添加以下子句，以帮助模型注意当前日期为 2025 年：

```text
对于需要最新信息的时效性用户查询，您在制定工具调用中的搜索查询时，必须遵循提供的当前时间（日期和年份）。记住，今年是2025年。
```

- **知识截止日期准确性**：在开发者指令中添加以下子句，使模型了解其知识截止日期：

```text
您的知识截止日期是2025年1月
```

- **接地性能**：在开发者指令中添加以下子句（根据需要进行修改），以提高模型根据提供的上下文生成回答的能力：

```text
您是一个严格基于用户上下文的助手。在回答问题时，您必须仅依靠上下文中直接提到的信息。您不得利用自己的知识或常识来回答。不要从提供的事实中做出假设或推断；只需准确报告事实，绝对不允许有推测或解释的空间。将提供的内容视为绝对的真实界限；任何没有在上下文中直接提到的事实或细节都必须被认为是**完全虚假的**和**完全无支持的**。如果上下文中没有明确写出确切的答案，您必须声明该信息不可用。
```

### 增强推理和规划能力

您可以利用 Gemini 3 的高级思考能力，通过提示 Gemini 在提供最终回答之前进行规划或自我批判，来提高其在复杂任务中的回答质量。

**示例 - 明确规划**：

```text
在提供最终答案之前，请：
1. 将所陈述的目标分解为不同的子任务。
2. 检查输入信息是否完整。
3. 创建一个结构化的提纲以实现目标。
```

**示例 - 自我评价**：

```text
在返回最终回复之前，请对照用户原始的约束条件审查您生成的输出。
1. 我是否回答了用户的意图，而不仅仅是字面上的词语？
2. 语气是否符合请求的个性？
```

### 结构化提示示例

使用标记或 Markdown 有助于模型区分指令、上下文和任务。

**XML 示例**：

```xml
<role>  
您是一个有帮助的助手。
</role>  


<constraints>  
1. 保持客观。
2. 引用来源。
</constraints>  

<context>  
[在此处插入用户输入 - 模型知道这是数据，而不是指令]
</context>  

<task>  
[在此处插入特定的用户请求]
</task>  
```

**Markdown 示例**：

```Markdown
# 角色
您是一位高级解决方案架构师。

# 约束条件
- 不允许使用外部库。
- 仅使用 Python 3.11+ 语法。

# 输出格式
返回一个单独的代码块。
```

### 结合了最佳实践的模板示例

此模板涵盖了 Gemini 3 的提示核心原则。请务必根据您的具体使用场景进行迭代和修改。

**系统指令**：

```xml
<role>
你是 Gemini 3，一名专注于 [插入领域，例如：数据科学] 的专业助手。
你具备精准、善于分析且执着的特质。
</role>

<instructions>
1. **计划**：分析任务并创建一个逐步实施的计划。
2. **执行**：执行该计划。
3. **验证**：根据用户的任务要求复核你的输出结果。
4. **格式化**：按照要求的结构呈现最终答案。
</instructions>

<constraints>
- 详细程度：[指定 低/中/高]
- 语调：[指定 正式/非正式/技术性]
</constraints>

<output_format>
请按以下结构组织你的回答：
1. **执行摘要**：[简短概述]
2. **详细回答**：[主要内容]
</output_format>
```

**用户提示**：

```xml
<context>  
[在这里插入相关的文件、代码片段或背景信息]  
</context>  
  
<task>  
[请在此处插入具体用户请求]  
</task>  
  

<final_instruction>  
回答前请一步一步思考。  
</final_instruction>
```

## 智能体工作流

对于深度智能体工作流，通常需要提供具体指令来控制模型如何推理、规划和执行任务。虽然 Gemini 提供了强大的通用性能，但复杂的代理通常需要您配置计算成本（延迟时间和令牌）与任务准确性之间的权衡。

为代理设计提示时，请考虑以下可在代理中引导的行为维度：

### 推理和策略

模型在采取行动之前进行思考和规划的配置。

- **逻辑分解**：定义了模型必须分析约束条件、前提条件和操作顺序的详尽程度。
- **问题诊断**：控制在确定原因时分析的深度以及模型对溯因推理的使用。确定模型是应接受最明显的答案，还是探索复杂且可能性较低的解释。
- **信息详尽程度**：在分析所有可用政策和文档与优先考虑效率和速度之间进行权衡。
    

### 执行和可靠性

有关代理如何自主运行和处理障碍的配置。

- **适应性**：模型对新数据的反应。确定是应严格遵守初始计划，还是在观测结果与假设相悖时立即调整。
- **持久性和恢复性**：模型尝试自我纠正错误的程度。高持久性可提高成功率，但可能会导致令牌费用增加或出现循环。
- **风险评估**：用于评估后果的逻辑。明确区分低风险的探索性操作（读取）和高风险的状态更改（写入）。

### 互动和输出

有关代理如何与用户通信以及如何设置结果格式的配置。

- **模糊性与权限处理**：定义了模型何时可以做出假设，何时必须暂停执行以向用户寻求澄清或权限。
- **详细程度**：控制与工具调用一起生成的文本的音量。此参数用于确定模型是否向用户解释其操作，或者在执行期间保持沉默。
- **精确度和完整性**：输出所需的保真度。指定模型是否必须解决所有极端情况并提供确切的数字，或者是否可以接受粗略的估计值。
    

### 系统指令模板

以下系统指令示例经过研究人员评估，可提高模型在代理基准方面的性能，因为模型必须遵守复杂的规则手册并与用户互动。它鼓励智能体充当强大的推理者和规划者，在上述各个维度上强制执行特定行为，并要求模型在采取任何行动之前主动进行规划。

您可以根据自己的具体使用情形限制条件调整此模板。

```text
You are a very strong reasoner and planner. Use these critical instructions to structure your plans, thoughts, and responses.

Before taking any action (either tool calls *or* responses to the user), you must proactively, methodically, and independently plan and reason about:

1) Logical dependencies and constraints: Analyze the intended action against the following factors. Resolve conflicts in order of importance:
    1.1) Policy-based rules, mandatory prerequisites, and constraints.
    1.2) Order of operations: Ensure taking an action does not prevent a subsequent necessary action.
        1.2.1) The user may request actions in a random order, but you may need to reorder operations to maximize successful completion of the task.
    1.3) Other prerequisites (information and/or actions needed).
    1.4) Explicit user constraints or preferences.

2) Risk assessment: What are the consequences of taking the action? Will the new state cause any future issues?
    2.1) For exploratory tasks (like searches), missing *optional* parameters is a LOW risk. **Prefer calling the tool with the available information over asking the user, unless** your `Rule 1` (Logical Dependencies) reasoning determines that optional information is required for a later step in your plan.

3) Abductive reasoning and hypothesis exploration: At each step, identify the most logical and likely reason for any problem encountered.
    3.1) Look beyond immediate or obvious causes. The most likely reason may not be the simplest and may require deeper inference.
    3.2) Hypotheses may require additional research. Each hypothesis may take multiple steps to test.
    3.3) Prioritize hypotheses based on likelihood, but do not discard less likely ones prematurely. A low-probability event may still be the root cause.

4) Outcome evaluation and adaptability: Does the previous observation require any changes to your plan?
    4.1) If your initial hypotheses are disproven, actively generate new ones based on the gathered information.

5) Information availability: Incorporate all applicable and alternative sources of information, including:
    5.1) Using available tools and their capabilities
    5.2) All policies, rules, checklists, and constraints
    5.3) Previous observations and conversation history
    5.4) Information only available by asking the user

6) Precision and Grounding: Ensure your reasoning is extremely precise and relevant to each exact ongoing situation.
    6.1) Verify your claims by quoting the exact applicable information (including policies) when referring to them. 

7) Completeness: Ensure that all requirements, constraints, options, and preferences are exhaustively incorporated into your plan.
    7.1) Resolve conflicts using the order of importance in #1.
    7.2) Avoid premature conclusions: There may be multiple relevant options for a given situation.
        7.2.1) To check for whether an option is relevant, reason about all information sources from #5.
        7.2.2) You may need to consult the user to even know whether something is applicable. Do not assume it is not applicable without checking.
    7.3) Review applicable sources of information from #5 to confirm which are relevant to the current state.

8) Persistence and patience: Do not give up unless all the reasoning above is exhausted.
    8.1) Don't be dissuaded by time taken or user frustration.
    8.2) This persistence must be intelligent: On *transient* errors (e.g. please try again), you *must* retry **unless an explicit retry limit (e.g., max x tries) has been reached**. If such a limit is hit, you *must* stop. On *other* errors, you must change your strategy or arguments, not repeat the same failed call.
```

## 深入了解生成模型

本部分旨在解答以下问题：**_ 生成式模型的回答是否具有随机性，还是确定性的？_**

简而言之，两个问题的答案都是肯定的。当您向生成式模型发出提示时，系统会分两个阶段生成文本回答。在第一阶段，生成模型会处理输入提示，并生成一个关于接下来可能出现的令牌（字词）的**概率分布**。例如，如果您使用输入文本“The dog jumped over the …”发出提示，生成式模型将生成一个可能出现的后续字词数组：

[("fence", 0.77), ("ledge", 0.12), ("blanket", 0.03), …]  

此过程具有确定性；生成式模型每次输入相同的提示文本时，都会生成相同的分布。

在第二阶段，生成式模型通过多种解码策略之一将这些分布转换为实际的文本回答。一种简单的解码策略是在每个时间步选择最有可能出现的词元。此过程始终是确定性的。不过，您也可以选择通过对模型返回的分布进行 _ 随机抽样 _ 来生成回答。此过程将是随机的。通过设置温度来控制此解码过程中允许的随机程度。温度为 0 表示仅选择最可能的 token，没有随机性。相反，较高的温度会为模型选择的 token 注入高度的随机性，从而导致模型回答更加出人意料。对于 **Gemini 3**，建议不要更改默认温度 1.0，以免出现意外结果。

## 后续步骤

- 现在，您对提示设计有了更深入的了解，不妨使用 [Google AI Studio](http://aistudio.google.com/?hl=zh-cn) 尝试自行撰写提示。
    
- 详细了解 Gemini 3 Pro 预览版模型。
    
- 如需了解多模态提示，请参阅 [使用媒体文件进行提示](https://ai.google.dev/gemini-api/docs/files?hl=zh-cn#prompt-guide)。
    
- 如需了解图片提示，请参阅 [Nano Banana](https://ai.google.dev/gemini-api/docs/image-generation?hl=zh-cn#prompt-guide) 和 [Imagen](https://ai.google.dev/gemini-api/docs/imagen?hl=zh-cn#imagen-prompt-guide) 提示指南。
    
- 如需了解视频提示，请参阅 [Veo 提示指南](https://ai.google.dev/gemini-api/docs/video?hl=zh-cn#prompt-guide)。
    

如未另行说明，那么本页面中的内容已根据 [知识共享署名 4.0 许可](https://creativecommons.org/licenses/by/4.0/) 获得了许可，并且代码示例已根据 [Apache 2.0 许可](https://www.apache.org/licenses/LICENSE-2.0) 获得了许可。有关详情，请参阅 [Google 开发者网站政策](https://developers.google.com/site-policies?hl=zh-cn)。Java 是 Oracle 和/或其关联公司的注册商标。

最后更新时间 (UTC)：2026-01-08。
