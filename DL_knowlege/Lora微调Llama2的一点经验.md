[原文](https://juejin.cn/post/7304538454875750427)

超参数

在深入讨论实验结果之前，先简要介绍一下在本文中作为 LoRA 配置基准所使用的超参数。

关于每种选择背后的理由仍然是 LLM 社区中的讨论热点，下文将对我们的决策进行阐述：

秩：8

选择更高秩的分解矩阵将抵消 LoRA 的效率优势。我们的初步测试表明，即使将秩提高到 16，性能提升也微乎其微。因此，我们选择秩为 8 以维持更小的检查点尺寸，避免人为地扩大检查点文件。

Alpha:16

Alpha 用于对学习到的权重进行扩展。包括原始的 LoRA 论文在内的现有文献，通常建议固定 Alpha 的值为 16，而不将其作为可调节的超参数。

目标模块：所有密集层

最初的 LoRA 论文专注于仅对“Q”和“V”注意力矩阵进行微调，并取得了可观的成果，证明了该技术的有效性。但随后的研究表明，对其他层甚至所有层进行微调能够改善效果。我们推测，将 LoRA 应用于更多的层可以使我们更接近于实现全参数微调的能力。因此，我们选择在所有层上实施 LoRA。

基础学习率：1e-4

学习率 1e-4 已成为使用 LoRA 微调 LLM 的标准。尽管我们在训练过程中偶尔会遇到训练损失不稳定的情况，但将学习率降低到 3e-5 等较低的值可有效稳定训练过程，关于这一点将在下文中详细讨论。