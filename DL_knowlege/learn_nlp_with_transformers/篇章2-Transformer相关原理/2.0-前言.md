## 前言
本章节将会对Transformer相关的原理进行深入讲解，主要涉及的内容有：attention，transformer和两个经典模型BERT和GPT。
* [2.1-图解attention](./篇章2-Transformer相关原理/2.1-图解attention.md)
* [2.2-图解transformer](./篇章2-Transformer相关原理/2.2-图解transformer.md)
* [2.2.1-Pytorch编写Transformer.md](./篇章2-Transformer相关原理/2.2.1-Pytorch编写Transformer.md)
* [2.2.2-Pytorch编写Transformer-选读.md](./篇章2-Transformer相关原理/2.2.2-Pytorch编写Transformer-选读.md)
* [2.3-图解BERT](./篇章2-Transformer相关原理/2.3-图解BERT.md)
* [2.4-图解GPT](./篇章2-Transformer相关原理/2.4-图解GPT.md)
* [2.5-篇章小测](./篇章2-Transformer相关原理/2.5-篇章小测.md)


