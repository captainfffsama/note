以下回答来自 grok3

Deformable attention 是一种在计算机视觉任务中广泛使用的注意力机制，特别是在像 Deformable DETR 这样的架构中，用于自适应地关注输入特征图中的相关区域。以下将详细描述其输入输出、计算流程，尤其是如何根据 query 的偏置来采样参考点，并附上一个简单的例子。

---

### 输入与输出

#### 输入
- **Query 特征**：一组向量，每个向量的维度为$D$，表示查询（例如在目标检测任务中为目标查询）。
- **特征图**：一个形状为$(H, W, C)$的张量，其中$H$和$W$分别是高度和宽度，$C$是通道维度。这个特征图通常来自卷积神经网络（CNN）或前一层的 transformer 输出。
- **位置信息**：在 deformable attention 中，位置信息通过从 query 预测的参考点和偏置来处理。

#### 输出
- 对于每个 query，输出是一个维度为$D$的向量，表示 deformable attention 特征。这个向量是从特征图中自适应选择的采样点位置提取的特征的加权和。

---

### 详细计算流程

Deformable attention 的核心思想是允许模型根据 query 动态选择特征图中的采样点，而不是像标准注意力机制那样使用固定位置。以下是详细的计算步骤：
1. **预测参考点**：
   - 对于每个 query，通过对 query 特征应用一个线性层，预测一个参考点$p$。这个参考点通常是一个二维坐标（对于图像任务），作为后续采样点的基准位置。

2. **预测偏置和注意力权重**：
   - 从 query 特征中预测以下内容：
     - **偏置**$\delta p_{mk}$：对于每个注意力头$m$（共$M$个头）和每个采样点$k$（每个头有$K$个采样点），预测一个偏置。这些偏置通过一个线性层输出，用于调整采样位置。
     - **注意力权重**$A_{mk}$：对于每个头$m$和每个采样点$k$，预测一个标量权重。这些权重通过另一个线性层输出，并对每个头的$K$个采样点应用 softmax 归一化。

3. **计算采样位置**：
   - 对于每个头$m$和每个采样点$k$，实际的采样位置为：
     $$
     p_{\text{sample}, mk} = p + \delta p_{mk}
     $$
     其中$p$是参考点，$\delta p_{mk}$是预测的偏置。

4. **从特征图中采样特征**：
   - 在每个采样位置$p_{\text{sample}, mk}$从特征图中提取特征。由于$p_{\text{sample}, mk}$可能是非整数坐标，通常使用双线性插值来计算对应的特征值。

5. **计算每个头的加权和**：
   - 对于每个注意力头$m$，将$K$个采样点的特征用预测的注意力权重组合：
     $$
     \text{head}_m = \sum_{k=1}^K A_{mk} \cdot z(p + \delta p_{mk})
     $$
     其中$z(p + \delta p_{mk})$是从特征图$z$在位置$p + \delta p_{mk}$采样的特征。

6. **应用线性投影并汇总所有头**：
   - 对每个头的输出应用线性投影$W_m$，然后对所有头的输出求和，得到该 query 的最终输出：
     $$
     \text{output} = \sum_{m=1}^M W_m \left( \sum_{k=1}^K A_{mk} \cdot z(p + \delta p_{mk}) \right)
     $$

---

### 根据 Query 的偏置采样参考点

采样点的位置由参考点$p$和偏置$\delta p_{mk}$共同决定，而这两者都由 query 预测：
- **参考点$p$**：直接从 query 特征通过线性层预测，确定采样的中心位置。
- **偏置$\delta p_{mk}$**：同样从 query 特征预测，调整采样点相对于参考点$p$的具体位置。

因此，query 通过预测参考点$p$和偏置$\delta p_{mk}$来影响采样过程，使得注意力机制能够根据 query 的内容动态聚焦特征图的不同区域。

---

### 简单例子

考虑一个简化的场景：
- 一个单独的 query。
- 一个$4 \times 4$的特征图（即$H = 4$,$W = 4$）。
- 一个注意力头 ($M = 1$) 和四个采样点 ($K = 4$)。

#### 计算步骤
1. **预测参考点**：
   - 假设从 query 预测的参考点为$p = (1.5, 1.5)$，即网格的中心。

2. **预测偏置**：
   - 模型预测四个采样点的偏置：
     $$
     \delta p_1 = (0.5, 0.5), \quad \delta p_2 = (-0.5, 0.5), \quad \delta p_3 = (0.5, -0.5), \quad \delta p_4 = (-0.5, -0.5)
     $$

3. **计算采样位置**：
   - 采样点位置为：
     $$
     p + \delta p_1 = (2.0, 2.0), \quad p + \delta p_2 = (1.0, 2.0), \quad p + \delta p_3 = (2.0, 1.0), \quad p + \delta p_4 = (1.0, 1.0)
     $$

4. **采样特征**：
   - 由于这些采样点都在整数坐标上，直接从特征图中提取对应位置的特征，即$z(2,2)$,$z(1,2)$,$z(2,1)$,$z(1,1)$。

5. **预测注意力权重**：
   - 假设注意力权重均匀分布：$A_1 = 0.25$,$A_2 = 0.25$,$A_3 = 0.25$,$A_4 = 0.25$。

6. **计算加权和**：
   - 该头的输出为：
     $$
     0.25 \cdot z(2,2) + 0.25 \cdot z(1,2) + 0.25 \cdot z(2,1) + 0.25 \cdot z(1,1)
     $$

7. **应用线性投影**：
   - 将上述和通过线性投影$W$处理，得到该 query 的最终输出特征。

#### 说明
在这个例子中，query 通过预测的偏置调整了采样点，使其围绕参考点$(1.5, 1.5)$分布在特征图的四个位置，从而实现了对特定区域的关注。

---

### 总结

Deformable attention 通过从 query 预测参考点和偏置，动态选择特征图中的采样点，使注意力机制能够自适应地聚焦于与任务相关的区域。这种灵活性使其在目标检测和图像分割等任务中表现出色。上述流程和例子展示了其核心思想和实现方式。