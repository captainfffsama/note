一. 损失函数
-------

### 1\. 对象损失

v5中使用[BCE](https://so.csdn.net/so/search?q=BCE&spm=1001.2101.3001.7020)来判断“该区域是否有对象”。在输出中根据此处输出来过滤无对象区域。  
![](https://img-blog.csdnimg.cn/2c3073eff68045adba43279190881cb1.png)

v8中**取消了这一损失**，改为用**分类损失**中，“该区域是否有此类对象”的[one-hot编码](https://so.csdn.net/so/search?q=one-hot%E7%BC%96%E7%A0%81&spm=1001.2101.3001.7020)形式来判断。

_个人理解：v5“判断对象有无”的形式，虽然能加速结果处理掩码的速度，但处理多分类问题时，该判据的可信度可能会随着类别数的增加、特征信息的互相影响而降低。同时另一方面，此损失的功能也被分类损失部分覆盖。  
v8在此方向的改进不仅提升了模型权重的利用率，还通过存在状态与分类状态的强关联，使得标签能更好指导模型对类别区分能力的学习。_

### 2\. 分类损失

##### BCE

v5/v8均使用BCE(二元交叉熵)作为分类损失，每类别判断“是否为此类”，并输出置信度。  
![](https://img-blog.csdnimg.cn/45e73d6e4e0a4f5b9506b44d2b0b639f.png)
  
v5中，由于有对象损失的存在，在反算时只对BCE分类输出的“置信度分数”做取最大值，得到置信度最大的类别，后直接输出。  
v8中，由于去掉了对象损失，在输出中也**去掉了“对象置信度”**，直接输出各个类别的“置信度分数”，再对其求最大值，将其作为此anchor框的“置信度”。  
![](https://img-blog.csdnimg.cn/2bf032c81483463d86d7cc53a4f1461d.png)

### 3\. 回归损失

##### CIOU

IOU(Intersection over Union、交集-并集比例)是一种描述框之间的重合度的方式。在回归任务中，可通过“目标框”与“预测框”的比值来衡量框的回归程度  
![](https://img-blog.csdnimg.cn/45adbee4c12943fda74055b7a6c425a6.png)

v5使用的**CIOU** loss用以令锚框更加接近标签值的损失，在(IOU)交并比损失上加上了宽高比的判据，从而更好在三种几何参数：重叠面积、中心点距离、长宽比上拟合目标框。  
![](https://img-blog.csdnimg.cn/fd33efd1fe84455fb3647da894ab47fb.png)

单独的CIOU loss的目标为“预测一个绝对正确的值(标签值)”，在数学上可以看做是一种“狄拉克分布”(一个点概率为无穷大，其他点概率为0)。  
如果把标签认为是"绝对正确的目标"，那么学习出的就是狄拉克分布，概率密度是一条尖锐的竖线。然而真实场景，物体边界并非总是十分明确的。  
![](https://img-blog.csdnimg.cn/75fbee786c9f40a8900e96da111d0b8e.png)

![](https://img-blog.csdnimg.cn/be4239be420d4f1691b588f346cf1c39.png)

##### CIOU + DFL

虽然v8的CIOU使用方式与v5保持一致，但引入**Anchor-Free**的Center-based methods(基于中心点)后，模型从输出“锚框大小偏移量(offest)”变为"预测目标框左、上、右、下边框距目标中心点的距离(ltrb = left, top, right, bottom)"。  
![](https://img-blog.csdnimg.cn/d32b8efef8de40988caade73d3dd43ee.png)

为配合Anchor-Free、以及提升泛化性，在v8中，增加了**DFL损失**。DFL以交叉熵的形式，去优化与标签y最接近的一左一右2个位置的概率，从而让网络更快的聚焦到**目标位置及邻近区域**的分布。  
![](https://img-blog.csdnimg.cn/cd659995e77440abb2a2039e87b53d14.png)

也就是说，学习的分布理论上是在真实浮点坐标的附近，并以线性插值的模式得到距离左右整数坐标的权重。  
![](https://img-blog.csdnimg.cn/9ab2072be0124639b2952b1a06973b83.png#pic_center)

这种学习标签周围位置的损失，能够增强模型在复杂情况下，如遮挡、移动物体时的泛化性。  
![](https://img-blog.csdnimg.cn/fb6f95f793514018b20f3f3d85c90484.png)
  
将标签转换为DFL形式的具体过程为：  
①将标签值xywh转换为ltrb  
②计算ltrb四个值，转换为DFL所需的积分形式（即预测值 + 临近预测值）  
具体转换过程为：y = 中心距某条边的距离 / 当前的下采样倍数  
**例如：**   
目标中心点距上边73 px，在最大下采样32倍的特征图中，计算其在DFL中的映射值为73 / 32 = 2.3。  
取整后得预测值yi = 2，  
临近预测值yi+1 = 3  
根据映射值与预测值、临近预测值的接近程度，计算各自的权重为  
2.3 - 2 = 0.3，  
3 - 2.3 = 0.7  
![](https://img-blog.csdnimg.cn/a5d7cdc93121456d945d0fb93e97dd05.png)
  
根据上述计算，其在DFL中的表达即为  
![](https://img-blog.csdnimg.cn/00ec34094dac4c66a827d729d24b2441.png)
  
在实际训练中，DFL将与CIOU损失结合使用。  
在第一部分，通过DFL对“边界框分布概率”和标签的“分布概率”进行损失计算，从而对每条边进行优化。  
在第二部分，将“边界框分布概率”还原为预测框，通过CIOU损失对预测框和标签的“实际框”进行损失计算，从而对预测框整体进行优化。  
![](https://img-blog.csdnimg.cn/3656d5724e24476e9a08618daecda074.png)

##### DFL的Reg_max

需要额外指出的是，DFL有一个隐藏的超参数——Reg_max。  
这个参数代表了“输出特征图中，ltrb预测的最大范围”。默认值为16，即能表示16个特征图单元所映射的实际距离。  
在v8中，最大下采样倍数为20。即在默认环境——640 x 360下，DFL能表达的最大单边距离为：320。能够覆盖此分辨率下的所有目标。  
![](https://img-blog.csdnimg.cn/44e0953a69e3472c91bd8e22e2cd99d6.png)

但此超参数Reg_max是固定值——16，如果你的输入是640，最大下采样到20 x 20的特征图，那么16是够用的。  
如果输入没有resize或者超过了640则需设置这个Reg_max参数，否则如果目标尺寸还大，将无法拟合到这个偏移量。  
如1280 x 1280的图片，目标1280 x 960，最大下采样32倍，1280/32/2=20 > 16(除以2是因为ltrb是一半的宽高)，超过了DFL的reg_max范围。  
同理，输入图像小于512 x 512，那下采样32倍后，特征图尺度就小于16，Reg_max就需要设定一个更小的值。

_个人理解：检测大图大目标/小图小目标时，要调整Reg_max。_

_个人理解：DFL通过将回归问题改造为分类问题，一方面提升了模型对复杂情况的预测能力；另一方面，在结合了Anchor-Free的思想后，通过ltrb的形式，拓展了单个特征图单元的表达能力，提升了预测框输出的利用率。_

二. Anchor-Based、Anchor-Free
---------------------------

概念：在目标定位任务里，由于目标的大小、尺寸都是不固定的，因此需要另一个框来预测目标的大概形状。  
深度学习中常见的方法是：将整个图分为多个区域，依次判断各个区域有无目标、目标大小、目标尺寸等。  
这些多个小区域被称为Anchor——即锚框，用以锚定实际的预测框。  
![](https://img-blog.csdnimg.cn/445ace20027f4469bfb3d22e29dceffb.png)

### 1\. Anchor-Based

##### 原理

根据训练集中所有标签的形状，计算(聚类)出基础的“覆盖面最广的多类框形状”，并令网络输出"偏移量"offset微调框尺寸，以更好预测形状。  
![](https://img-blog.csdnimg.cn/a5253dc7a8704b4c840746fad77923ac.png)

v5中Anchor-Based的使用方式为one_stage——在网络的多尺度上展开anchor boxes，以直接预测物体的类别和 anchor box偏移量。  
v5中目标的反算为：特征图数据 * 预设锚框参数的宽高 = 目标的位置（并不是直接预测目标的位置）。  
其中特征图数据则包含了中心点偏移量、宽高偏移量等数据。  
在V5中，反算得到的预测框有:(52×52 + 26×26 + 13×13) × 3 = 10647个。  
![](https://img-blog.csdnimg.cn/4fb9d486d9a442f49a50324723a44644.png)

_个人理解：显然，由于Anchor-Based对框形状的预先定义，使其在确定的数据环境中有极好的表现，在学术研究或固定环境检测中有较好的发挥。而也因为这点，在面对复杂环境时，Anchor-Based对物体的表达能力会较为吃力。_

### 2\. Anchor-Free

##### Anchor-Based的局限性

①Anchor的设置需要手动去设计(长宽比，尺度大小，anchor的数量），对不同数据集也需要不同的设计，相当麻烦。  
②Anchor的匹配机制使得极端尺度(特别大/小的object)被匹配到的频率，相对于大小适中的object被匹配到的频率更低，网络在学习时不容易学习这些极端样本。  
③Anchor的庞大数量使得存在严重的不平衡问题，涉及到采样、聚类的过程。但聚类的表达能力在复杂情况下是有限的  
④Anchor-Based为了兼顾多尺度下的预测能力，推理得到的预测框也相对较多，在输出处理时的nms计算也会更加耗时。

##### 原理

训练中直接学习各种框形状。推理时**不依靠聚类**，而是根据学习到的边框距离/关键点位置，拟合物体尺寸。  
v8中使用的方法是：Center-based methods——基于中心点的方法。先找中心/中心区域，再预测中心到四条边的距离。  
![](https://img-blog.csdnimg.cn/a7e63b8504ca45dd841be567738e6aca.png)

v8中目标的反算为：在特征图每个grid(特征图中的单个框)上，预测框四条边与grid中心点的偏移值 (“左上右下”相对于中心点的距离)。  
其中四条边偏移量将通过直接将16个格子进行积分(离散变量为求和，也就是期望)，再乘以下采样倍数来得到。  
在V8中，反算得到的预测框有:(80x80 + 40x40 + 20x20) = 8400个。  
注：v8默认的最大下采样倍数为32。  
![](https://img-blog.csdnimg.cn/acab056a97984a67ab9d4279a8ef8921.png)

_个人理解：Anchor-Free通过不依赖数据集中的先验知识，使网络对“物体形状”有更好的表达能力，更具泛化潜能。在运动物体、尺寸不一物体检测上有所提升，同时检测被遮挡物体时也能更加灵活。_

三. 样本分配策略
---------

概念：在目标定位任务里，由于在图片中，有目标的区域总是少量的，更多的是无目标区域。如果只判断“什么是目标”，会导致大量的误识别。  
所以，除了用“有目标区域”训练“什么是目标”外，还需要用“无目标区域”训练“什么不是目标”。  
这就衍生出了一个问题：网络不知道哪里是“有目标区域”。  
这个区域——我们称之为**正样本**——需要人为的定义。同上，正样本总很少，负样本(即无目标区域)总太多。会导致模型学习不均衡。因此，我们需要**样本分配策略**来解决这一问题。

### 1\. 静态策略

静态分配策略是训练开始之前就确定的，这种分配策略通常基于经验得出，可以根据数据集的特点进行调整。  
但是不够灵活，可能无法充分利用样本的信息，导致训练结果不佳。

##### 正样本增样

v5中采用通过多种方式对正样本的进行增样，如跨分支采样、跨grid采样、anchor采样等方式。  
正负样本间的划分基于anchor与GT(标签样本)的iou阈值来定义正样本

跨分支采样：在三种尺寸的特征图上都对GT进行匹配。  
![](https://img-blog.csdnimg.cn/35286bb517fc4e0394ec6986cbcbce64.png)

跨grid采样：若GT框落在某网格内，将对此网格左、上、右、下4个邻域网格内“离GT中心位置较近”的两个网格作为正样本。  
例：下图中GT离左上更近，则选择上、右网格作为正样本  
![](https://img-blog.csdnimg.cn/cf694c47b50f4e0da528153d3a25406e.png)

跨anchor采样：根据宽高比匹配正样本。如果anchor和GT框的宽高比小于阈值（在源码中默认设置为4），就匹配成功。  
可理解为GT框满足一个聚类anchor宽和高的×0.25倍和×4.0倍之间就算匹配成功。如下图，AT2和AT3匹配成功  
![](https://img-blog.csdnimg.cn/6776ea5b9599455da646d4c03bf299b2.png)
  
![](https://img-blog.csdnimg.cn/939783b2ae084a6c972f71c3df0a9179.png)

即v5中一个GT框可以由多个分支、多个网格、多个anchor同时负责，一个目标最多可有9~27个正样本。  
_个人理解：虽然得益于预测广度的增加，增加了正样本数量，但由于0.25~4.0的判据仍基于聚类的anchor得到，灵活性和表达能力仍有不足。_

### 2\. 动态策略

动态分配策略可根据训练的进展、样本的特点动态调整权重  
在训练初期，模型可能会很难区分正负样本，此时权重惩罚值很大，会更关注容易被错分的样本。  
随着训练的进行，模型组件变得更加强大，可以更好地区分样本，因此权重的惩罚值就会动态的变低。  
**动态分配策略可根据训练损失或其他指标来调整，可更好地适应不同的数据集和模型。** 

##### Task alignment learning(TAL)任务对齐学习

任务对齐学习根据分类与回归的分数加权的分数选择正样本，使得样本分配能力可随着训练而不断增强，补充模型在不同任务上对正样本的需求。

TAL核心公式——“anchor质量计算式”：用分类质量与回归质量加权乘积描述anchor的预测质量。通过训练，t可以引导网络动态的关注于高质量的正样本。  
![](https://img-blog.csdnimg.cn/652cab956c5646cf8843da2a26b29828.png)

TAL实现动态分配的逻辑——使用分类得分和IoU的组合来衡量任务对齐的程度。  
使用上面公式对每个GT框实例计算Anchor-level 的对齐程度：s 和 u 分别为分类得分和 IoU 值，α 和 β 为权重超参(v8默认值α=0.5、β=6.0)。  
t 可同时通过分类得分和IoU 的优化来实现任务对齐，可引导网络动态的关注于高质量的Anchor预测框。  
采用一种简单的分配规则选择训练样本：对每个GT框实例，选择m个具有最大t 值的Anchor作为正样本，选择其余的Anchor作为负样本。  
然后，通过损失函数(针对分类与定位的对齐而设计的损失函数)进行训练。

TAL分配样本的具体流程：  
①预处理：  
对类别、边框、特征图各anchor中心点进行处理  
类别：进行sigmoid处理  
边框：还原到网络输入尺度  
中心：还原到网络输入尺度  
对标签数据也做同样处理，开始做正样筛选  
②初筛：对所有中心点在GT框中的anchor作为初步正样本。  
③精筛：计算上一步中anchor的**对齐分数alignment_metrics**（即t），选择分数最高的\*\*topk个候选框(默认为10)\*\*作为正样本。  
④去除重复分配：通过mask矩阵与anchor求和，找出分给多个GT框的anchor，只留下CIOU值大的anchor。  
⑤获得每样本对应的训练标签：通过上述步骤得到的掩码——anchor的正负样本、GT对应的正负样本、GT对应的正样本anchor索引，得到筛选出的正样本训练信息。

_个人理解：动态样本分配的策略能指导网络学习到更广泛的目标数据，而TAL通过使分类、回归加权指标来描述框的质量，更能指导模型在两种任务中薄弱那一方进行加强学习。通过提升正样本质量而非数量的策略，更能使网络的训练效率和质量有所提升。_

_值得指出的是，TAL官方论文中有提到，在对齐质量公式中的α、β是固定值，是由于团队对α、β的值做过学习性实验，将α、β也作为网络的一部分来优化数据。但发现随着α、β的更新，网络很容易进入局部最优状态，遂将α、β设置为固定值。  
但团队也指出，α、β的值可以根据具体任务来做一些微调，能够取得一些优化。_