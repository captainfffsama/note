---

kanban-plugin: board

---

## VLA 待看论文

- [ ] Diffusion-VLA: Generalizable and Interpretable Robot Foundation Model via Self-Generated Reasoning.
- [ ] Task Reconstruction and Extrapolation for π0 using Text Latent
- [ ] Improving Vision-Language-Action Model with Online Reinforcement Learning
- [ ] GRAPE:Generalizing Robot Policy via Preference Alignment
- [ ] What Can RL Bring to VLA Generalization? An Empirical Study
- [ ] VLA-RL: Towards Masterful and General Robotic Manipulation with Scalable Reinforcement Learning
- [ ] ConRFT
- [ ] DexVLA
- [ ] UniVLA
- [ ] RoboTransfer
- [ ] [流匹配策略梯度 --- Flow Matching Policy Gradients](https://flowreinforce.github.io/)
- [ ] [[2508.07917] MolmoAct: Action Reasoning Models that can Reason in Space](https://arxiv.org/abs/2508.07917)
- [ ] [[2506.21230] World-aware Planning Narratives Enhance Large Vision-Language Model Planner](https://arxiv.org/abs/2506.21230)
- [ ] [[2508.09032] Spatial Traces: Enhancing VLA Models with Spatial-Temporal Understanding](https://arxiv.org/abs/2508.09032)
- [ ] NIPS 教程
	[《NeurIPS 2024 讲座》 --- NeurIPS 2024 Tutorials](https://neurips.cc/virtual/2024/events/tutorial)
- [ ] COLA: Learning Human-Humanoid Coordination for Collaborative Object Carrying
- [ ] [[2510.16732] A Comprehensive Survey on World Models for Embodied AI](https://www.arxiv.org/abs/2510.16732)
- [ ] [Streaming Flow Policy: Simplifying diffusion/flow policies by treating action trajectories as flow trajectories | OpenReview](https://openreview.net/forum?id=ay5lYpmywr)
- [ ] [FoAR: Force-Aware Reactive Policy for Contact-Rich Robotic Manipulation | OpenReview](https://openreview.net/forum?id=cbjluXVaJz)


## Manipulation 待看论文

- [ ] [[2510.11072] PhysHSI: Towards a Real-World Generalizable and Natural Humanoid-Scene Interaction System](https://arxiv.org/abs/2510.11072)
- [ ] [ReLIC](https://relic-locoman.rai-inst.com/)
- [ ] [[2512.01061] Opening the Sim-to-Real Door for Humanoid Pixel-to-Action Policy Transfer](https://arxiv.org/abs/2512.01061)
- [ ] [[2510.10903v1] Towards a Unified Understanding of Robot Manipulation: A Comprehensive Survey](https://arxiv.org/abs/2510.10903v1)
- [ ] [InterMimic: Towards Universal Whole-Body Control for Physics-Based Human-Object Interactions](https://arxiv.org/html/2502.20390?_immersive_translate_auto_translate=1)
- [ ] [LeCAR-Lab/HDMI](https://github.com/LeCAR-Lab/HDMI)
- [ ] [[2509.20322] VisualMimic: Visual Humanoid Loco-Manipulation via Motion Tracking and Generation](https://arxiv.org/abs/2509.20322)
- [ ] [[2505.24198] Hold My Beer: Learning Gentle Humanoid Locomotion and End-Effector Stabilization Control](https://arxiv.org/abs/2505.24198)


***

## 归档

- [ ] FAST : Efficient Action Tokenization for Vision-Language-Action Model.
- [ ] SpatialVLA Exploring Spatial Representations for Visual-Language-Action Models.
- [ ] [[2508.09071] GeoVLA: Empowering 3D Representations in Vision-Language-Action Models](https://arxiv.org/abs/2508.09071)
- [ ] [Reactive Diffusion Policy: Slow-Fast Visual-Tactile Policy Learning for Contact-Rich Manipulation | OpenReview](https://openreview.net/forum?id=zRhjjLGUAp) ^g1xz5l
- [ ] [[[2511.14756v1] HMC Learning Heterogeneous Meta-Control for Contact-Rich Loco-Manipulation](https arxiv.org abs 2511.14756v1)]([[2511.14756v1]%20HMC%20Learning%20Heterogeneous%20Meta-Control%20for%20Contact-Rich%20Loco-Manipulation](https%20arxiv.org%20abs%202511.14756v1).md)

%% kanban:settings
```
{"kanban-plugin":"board","list-collapse":[false,false]}
```
%%