#自监督 

[toc]

- 论文: <https://readpaper.com/pdf-annotate/note?pdfId=4745545008782786561&noteId=1816025687761446400>
- 代码: <https://github.com/facebookresearch/dinov2>
- 作者团队: META

# 全文关键点翻译
## 摘要

近年来, 自然语言处理 (NLP) 领域上使用大规模数据来对模型进行预训练的突破, 为视觉领域基础模型的工作开辟了道路. 这些模型可以产生通用的视觉特征, 可以极大的简化在各个系统中图像的处理. 即这些通用特征可以在不同的图片分布和任务上使用而无需微调. 现有的预训练方法, 特别是自监督方法, 是可以通过在足量的不同来源且精心筛选的数据上训练来得到这样的通用特征的. 我们回顾了现有方法, 并结合不同的技术来调整在不同的模型和数据规模上进行预训练的方法. 现有多数方法主要旨在加速和稳定大规模训练. 而本文在数据方面, 我们构建了一套自动化流水线来构建一个专用的, 多样的精心筛选的数据集, 而不是像其他自监督方法那样使用杂乱没有筛选的数据训练. 模型方面, 我们训练了一个 1 B 参数的 ViT, 并将其蒸馏成了一堆小模型. 这些模型在多数图像和像素级基准上都超越了现有的最好的通用特征模型, OpenCLIP.

## 1. 引言

学习一个任务无关的预训练表征是 NLP 中的基础工作. 人们可以无需微调的 " 按原样 " 使用这些特征, 就可以在下游任务上取得比特定任务模型还要好的效果. 而实现这种效果的方式通常是使用大规模的原始文本来对语言模型或词向量进行无监督预训练.

参照 NLP, 我们期望视觉邻域也可以有这样一个模型. 即这些模型无论是在图像级任务 (比如图像分类) 还是像素级任务 (比如分割), 都可以产生一个开箱即用的特征. 实现这个目标最有希望的方向是文本指导预训练, 即使用文本监督指导特征的训练. 但是这种文本指导预训练的方法限制了模型保留图像信息的丰富性, 毕竟文本只是图像信息的一种精简, 而一些复杂的像素级信息不会在此类监督训练中保留. 另外, 这些图像编码器需要图文对齐的语料库来训练, 不能直接使用原始数据训练.

而另一种有希望的方向是自监督学习, 即仅使用图片学习特征. 这类方法从概念上来说更接近于语言建模任务, 他们可以获取图片或者像素级的信息. 尽管这个方向看上去可以学到一个通用特征, 但是目前大部分的工作还是在一个相对较小的数据集 (ImageNet-1 k) 上进行的. 虽然也有一些工作尝试在更大数据规模上进行, 但是他们主要使用的是一些很粗糙的数据集, 这通常会导致特征的质量显著下降. 因为这类数据确实对数据质量和多样性的控制, 而这两个要素对产生好特征是至关重要的.

本文, 我们将探索自监督学习是否可以在一个大规模且高质量的数据集上学到一个通用视觉特征. 我们回顾了现有的可以学习图片和像素级特征的判别式自监督方法, 比如 iBOT, 并在更大数据集下重新思考了它们的设计. 我们大部分的技术都旨在在不同规模的模型和数据规模上实现稳定且高效的判别式自监督学习. 这些改进使得我们方法比一般判别式自监督方法快 2 倍, 内存上省 3 倍.

对于预训练数据, 我们则建立了一个自动流水线来过滤和平衡那些未整理的图片. 这是启发自 [Wenzek 等人](https://readpaper.com/paper/2989539713) 的 NLP 工作, 即主要利用数据间的相似性而且外部元数据, 且不需要人工标注. 处理这些图片的一大难点是如何平衡多样性, 避免在某几个域 (dominant) 上过拟合. 使用基本的聚类方法就可以较好的解决这个问题. 我们收集来一个小而多样, 大约 142 M 张图片的数据集来验证我们的方法.

最后, 我们提供了各种预训练模型 (搞笑泥浆去尿), 即 DINOv 2, 它是使用我们数据训练的各种 ViT 模型. 我们还开源了所有模型和代码, DINOv 2 可以在任意数据上复现. 如图 2 所示, 我们在不同视觉任务基准上测试了 DINOv 2. 结果表明, 自监督预训练是可以学到一个较通用的冻结特征参数, 其效果可以和目前公开的最佳弱监督模型相媲美.

![dinov2_meta_fig1](../../Attachments/dinov2_meta_fig1.png)

![dinov2_meta_fig2](../../Attachments/dinov2_meta_fig2.png)

## 2. 相关工作
### 图像内部自监督训练

自监督方法的第一大类是专注于从图像构建角度来进行建模, 比如从图片的剩余部分中获得监督信号 **(已知一部分预测剩下一部分)** .这个思路来源于 Doersch 等人 2015 年的工作, 他们通过预测给定图像块的上下文来进行训练. 还有很多工作是基于图像重新着色, 预测图像转换, 图像修复或者图像块重排序. 而最近, 随着基于 patch 的架构, 比如 ViT 的出现, 学界开始回顾图片修复做预训练, 包括在特征空间中做图像修复. 值得一提的是, He 等人的工作, MAE 效果不错, 其学到的特征在下游任务微调时可以提点. 然后其他人借鉴 MAE, 将其应用在来视频等其他模式上. 然而他们的特征依然需要监督微调, 而**我们的特征是开箱即用的**.

### 判别式自监督训练

### 自监督预训练的缩放

### 数据自动管理

## 3. 数据处理
## 4. 自监督式判别预训练
## 5. 实现细节
## 6. 消融实验
### 6.1 训练策略优化
### 6.2 预训练数据源
### 6.3 模型和数据规模
### 6.4 损失的组成
### 6.5 知识蒸馏影响
### 6.6 分辨率影响

## 7. 结果
### 7.1 ImageNet 分类
### 7.2 其他图像和视频分类基准
### 7.3 实例识别
### 7.4 密集识别任务
### 7.5 定性结果

## 8. 公平性和偏见分析
### 8.1 地理公平性
### 8.2 性别, 肤色, 年龄公平性

## 9. 模型训练时的环境影响

## 10. 展望


# 相关解析参考
- <https://ai.facebook.com/blog/dino-v2-computer-vision-self-supervised-learning/>
- <https://levelup.gitconnected.com/meta-dino-how-self-supervised-learning-is-changing-computer-vision-1666a5e43dbb>
- <https://zhuanlan.zhihu.com/p/623274167>
