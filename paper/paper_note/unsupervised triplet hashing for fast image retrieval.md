#无监督 #图像检索 

[toc]
# 摘要
本文是用来做大规模图片索引的.名字叫无监督三元组哈希法 (UTH) ,依据以下三规则设计:
- 对于图片索引有更强的鉴别性(既保证相似语义图片类间差小,也保证不同语义图片类间差大?)
- 原始特征描述算子和学习到的哈希码之间量化损失最小
- 学习到的特征码的信息熵最大

#  引言
Restricted Boltzmann Machines(RBMs) 需要预训练且复杂.一些使用图片增强的方法效果不错,尤其带旋转的,通过尝试原始图片和旋转图片的的二进制码距离来实现.但是这种方法也仅仅只提供了正样本,不能确保模型能区分不同语义图片的二进制码.
本文是可以区分不同语义图片的 hash 码的.主要创新点:
- 用三元组损失替换了 DeepBit 中的旋转不变损失
- 使用无标签的数据构造三元组
- 三元组损失可以强行平衡训练数据,而旋转不变损失是不考虑负样本的

# 相关工作
略

# 我的方法
$L_T$ 表示三元组损失,使得图像索引有更多的判别性(Ag 图片和原始图片相近,随机图片和原始图片较远),$L_Q$表示原始特征和学习到的哈希码的之间的量化损失,$L_E$表示哈希码的信息熵损失函数.最终损失是:
$$
L=\alpha L_T+ \beta L_Q+ \gamma L_E \tag{1}
$$

## 无监督的三元组损失$L_T$
对于一个未标注的数据集,使用原始图片 $p$ 和旋转图片 $p^+$ 和随机的另一张图片 $p^-$ 组成三元组, 则:
$$
L_T=\max{\{0,m+||F(p)-F(p^+)||_2^2-||F(p)-F(p^-)||_2^2\}}   \tag{2}
$$

$F$为学习到的哈希函数,$m$为设置的边界.

## 量化损失$L_Q$
在哈希层后额外加一层 ReLU 激活层.二进制码 $b$ 通过量化输出特征来生成,即对输出的函数$F(p)$取个阈值二值化:
$$
b=
\begin{cases}
	1,  & \text{if $F(p)$ > threshold} \\
	0, & \text{otherwise} \\
\end{cases}
\tag{3}
$$
本文实验中,我们设置阈值为0.5,并将输出的特征$F(p)$和量化之后的特征码之间平方差作为正则来缩小差异.其实就是为了保证特征码尽量携带更多的最终特征信息.得到:
$$
L_Q=\sum_{n=1}^N \sum_{m=1}^M ||F(p)-b||^2  \\
=
\begin{cases}
	\sum_{n=1}^N \sum_{m=1}^M ||F(p)-1||^2 ,  & \text{if $F(p)$ > 0.5} \\
	\sum_{n=1}^N \sum_{m=1}^M ||F(p)||^2 , & \text{otherwise} \\
\end{cases}
\tag{4}
$$
$N$ 是训练数据的数量, $M$ 是哈希码的长度

## 信息熵损失$L_E$
根据 DeepBit 和信息论启发,编码中每个单元的信息分布约均匀,那么信息熵越大.因此我们添加了一个正则:
$$
L_E=\sum_{m=1}^M (u_m -0.5)^2, u_m= \frac{1}{N} \sum_{n=1}^N b_n(m) \tag{5}
$$

#  实验
## 实验设置
优化方法SGD,使用VGG作为于训练,然后添加一个 ReLU 进行激活.三元组共享权重.旋转图片是分别旋转 $\pm 10$,$\pm 5$,训练时设置 $\alpha =\beta=\gamma=1$.先使用原始的训练数据训练网络,收敛目标是最小化量化损失和信息熵损失,然后在使用三元组损失来微调. 对于 CIFAR-10 和 MNIST 数据集分别设置哈希为 16位,32位,64位,对于 In-shop 数据设置哈希为 64位,128位,256位.

# 个人思考
没代码,看不到整个网络架构,但是这里哈希也能算是一个启发