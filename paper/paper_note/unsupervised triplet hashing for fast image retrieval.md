#无监督 #图像检索 

[toc]

# 摘要

本文是用来做大规模图片索引的.名字叫无监督三元组哈希法 (UTH) ,依据以下三规则设计:

- 对于图片索引有更强的鉴别性 (既保证相似语义图片类间差小,也保证不同语义图片类间差大?)
- 原始特征描述算子和学习到的哈希码之间量化损失最小
- 学习到的特征码的信息熵最大

#  引言

Restricted Boltzmann Machines(RBMs) 需要预训练且复杂.一些使用图片增强的方法效果不错,尤其带旋转的,通过尝试原始图片和旋转图片的的二进制码距离来实现.但是这种方法也仅仅只提供了正样本,不能确保模型能区分不同语义图片的二进制码.

本文是可以区分不同语义图片的 hash 码的.主要创新点:

- 用三元组损失替换了 DeepBit 中的旋转不变损失
- 使用无标签的数据构造三元组
- 三元组损失可以强行平衡训练数据,而旋转不变损失是不考虑负样本的

# 相关工作

略

# 我的方法

$L_T$ 表示三元组损失,使得图像索引有更多的判别性 (Ag 图片和原始图片相近,随机图片和原始图片较远),$L_Q$ 表示原始特征和学习到的哈希码的之间的量化损失,$L_E$ 表示哈希码的信息熵损失函数.最终损失是:

$$
L=\alpha L_T+ \beta L_Q+ \gamma L_E \tag{1}
$$

## 无监督的三元组损失 $L_T$

对于一个未标注的数据集,使用原始图片 $p$ 和旋转图片 $p^+$ 和随机的另一张图片 $p^-$ 组成三元组, 则:

$$
L_T=\max{\{0,m+||F(p)-F(p^+)||_2^2-||F(p)-F(p^-)||_2^2\}}   \tag{2}
$$

$F$ 为学习到的哈希函数,$m$ 为设置的边界.

## 量化损失 $L_Q$

在哈希层后额外加一层 ReLU 激活层.二进制码 $b$ 通过量化输出特征来生成,即对输出的函数 $F(p)$ 取个阈值二值化:

$$
b=
\begin{cases}
	1,  & \text{if $F(p)$ > threshold} \\
	0, & \text{otherwise} \\
\end{cases}
\tag{3}
$$

本文实验中,我们设置阈值为 0.5,并将输出的特征 $F(p)$ 和量化之后的特征码之间平方差作为正则来缩小差异.其实就是为了保证特征码尽量携带更多的最终特征信息.得到:

$$
L_Q=\sum_{n=1}^N \sum_{m=1}^M ||F(p)-b||^2  \\
=
\begin{cases}
	\sum_{n=1}^N \sum_{m=1}^M ||F(p)-1||^2 ,  & \text{if $F(p)$ > 0.5} \\
	\sum_{n=1}^N \sum_{m=1}^M ||F(p)||^2 , & \text{otherwise} \\
\end{cases}
\tag{4}
$$

$N$ 是训练数据的数量, $M$ 是哈希码的长度

## 信息熵损失 $L_E$

根据 DeepBit 和信息论启发,编码中每个单元的信息分布约均匀,那么信息熵越大.因此我们添加了一个正则:

$$
L_E=\sum_{m=1}^M (u_m -0.5)^2, u_m= \frac{1}{N} \sum_{n=1}^N b_n(m) \tag{5}
$$

#  实验
## 实验设置

优化方法 SGD,使用 VGG 作为于训练,然后添加一个 ReLU 进行激活.三元组共享权重.旋转图片是分别旋转 $\pm 10$,$\pm 5$,训练时设置 $\alpha =\beta=\gamma=1$.先使用原始的训练数据训练网络,收敛目标是最小化量化损失和信息熵损失,然后在使用三元组损失来微调. 对于 CIFAR-10 和 MNIST 数据集分别设置哈希为 16 位,32 位,64 位,对于 In-shop 数据设置哈希为 64 位,128 位,256 位.

# 个人思考

没代码,看不到整个网络架构,但是这里哈希也能算是一个启发