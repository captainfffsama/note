#无监督 #对比学习

[toc]

# 摘要
三点结论:
1. 数据增强的组合扮演来重要角色
2. 在表征层和对比损失之间引入一个可学习的非线性变换来提高表征学习的质量
3. 与监督学习相比,对比学习需要更大的 batch-size 和更多训练步数

# 引言
传统无监督常用的两个方向是生成和判别.但是生成方法计算量大且对表征学习没什么用,判别算法需要设计一些具体任务来进行模型训练,这会限制表征学习的能力.   
本文提出来一个方法 SimCLR 不依赖特定结构和天文算力的网络结构来进行视觉表征学习.通过研究这个框架,我们得到以下一些结论:
- 数据增强操作的组合影响很大.
- 在表征层和对比损失之间引入一个可学习的非线性变换来提高表征学习的质量
-  使用对比交叉熵的表征学习受益于归一化嵌入层和调参技巧
-  对于学习更加依赖于大网络,大批量和更多训练步数.

# 方法
## 对比学习框架
受同行启发, SimCLR 通过最大化同一图片不同增强的视图在隐空间下的对比损失来学习表征的. 它主要包含以下四个模块:
- 一个复杂的数据增强模块.将一张图片分别进行2次增强得到两张图片$\tilde{x}_i$和$\tilde{x}_j$,这里我们用的增强有随机裁剪,随机颜色抖动和随机高斯模糊,其中随机裁剪和颜色抖动对性能影响较大.
- 一个编码网络$f(\cdot)$用来提取增强数据的表征向量.这个编码网络对网络结构没有限制,这里我们使用 ResNet ,则 $h_i=f(\tilde{x}_i)=ResNet(\tilde{x}_i)$  这里 $h_i$ 是平均池化之后的输出.
- 一个网络头 $g(\cdot)$ 将表征映射到有对比损失的隐空间.这里我们使用一层的感知机,激活使用 ReLU.
- 对比损失函数.将包含 $\tilde{x}_i$和$\tilde{x}_j$的集合记作 $\{\tilde{x}_k\}$,对比预测的任务就是识别对于给定的$\tilde{x}_i$ 识别 $\tilde{x}_j$ 是不是在  $\{\tilde{x}_k\} _{k \neq{i}}$