#异常检测 

[toc]

# CSI: Novelty Detection via Contrastive Learningon Distributionally Shifted Instances

- 论文: <https://arxiv.org/abs/2007.08176>
- 代码: <https://github.com/alinlab/CSI>
- 会议: NeurIPS 2020

## 摘要  

新颖性检测是识别给定样本是否来自训练分布.为此,很多人都尝试学习一种适合这种任务的表征方法,并基于表征方法来设计分数.本文提出了一种名为对比漂移实例 (contrasting shifted instances,CSI), 其灵感来自最近大热的对比学习 (contrastive learning).本文方法不仅和其他实例进行对比,同时还将和自己的增强实例进行对比.为此,我们设计另一种新颖的检测分数.实验显示我们方法很赞.

##  1.引言

分布外检测 (Out-of-distribution,OOD),也叫新颖性检测或是异常检测,用来鉴别测试输入是否远离训练分布.OOD 的样本空间是十分巨大的,一个 OOD 样本也许就可以显著的改变整个训练样本分布.因此我们可以假设一个先验指示,特定的离群点可能会给检测器带来偏差. OOD 检测是一个经典而重要的机器学习问题,在医药检测,故障探伤,自动驾驶等领域有非常广泛的应用.  

常见的工作按照思想可以分为: 

- 基于密度的,
- 基于重建的
- 单类分类的
- 自监督的
最近大多数相关的工作都着眼于如何获得更好的表征来对正常样本编码,以及定义一个新的检测衡量分数.最近一些研究表明,自监督学习中的偏差归纳 (inductive bias) 可以有效帮助 OOD 检测来学习到更好的判别特征.  

与此同时,最近自监督学习的一些最新研究成果也证明了对比学习在计算机视觉,音频处理和强化学习上都是卓有成效的.对比学习通过使得类似的目标相互聚集,不同目标彼此排斥,从来在多个类似样本中得到较好的归纳偏差.[实例判别](https://zhuanlan.zhihu.com/p/91347205) 就是一个典型的对比学习,其视图 (view) 变换被限制在不同的数据增强中,然后依赖这些增强取得更好的视觉表征.

受到最近实例判别的启发,我们尝试将其表征学习能力应用于 OOD 检测.由此,引申出下列问题:

- a.如何学习到一个更具判别性的表征
- b.如何设计一个有效的分数函数来度量 a 中得到的表征.
注意, 用于 OOD 的表征学习旨在更好鉴别分布内和离群点的不同,而标准的表征学习则更加着重在判定分布内所有样本的不同.  

我们率先发现,设计一个合适的检测分数,现有的对比学习方法已经可以较好的进行 OOD 检测了.同时我们发现,使用诸如旋转等 " 硬 " 增强,可以进一步提高其性能,而这类增强方法在标准的对比学习中是有害的.具体而言,标准对比学习尝试将所有增强样本聚集向原始样本,而使用了 " 硬 " 增强或者分布漂移的增强方法会将增强样本推离原始样本.而我们发现,使用分布漂移的样本是有益于 OOD 检测的,模型不仅会尝试分辨分布内的点,还会学习分辨分布内和分布外的点.   

**贡献.**  
本文提出了 CSI.在现有对比学习基础上,提出了两个新颖的模块:

- a. 一种新的训练方式,这种方式不仅兼顾了以前的目标,还将分布漂移增强的样本和其他实例进行了对比
- b. 一种新的分数函数,它充分利用了对比学习的表征能力和我们新型训练方式的成功.    
最后,我们将 CSI 用于改进分类器的自信度校准: 在保持分类准确度的同时,这缓解了分类器在预测分布内和分布外样本时对于预测结果过分自信的情况.  

我们验证了 CSI 在各种环境下进行 OOD 检测的有效性,包括无标签单类,无标签多累和有标签多类等情况.据本文所知, CSI 是第一个可以同时适用于这三种情况的框架.在单类分类中,CSI 取得了 SOTA 结果, 对于 CIFAR-10,AUROC 从 90.1% 提高到 94.3%, CIFAR-100 上,从 79.8% 提到到了 89.6%,在 ImageNet-30 上,从 85.7% 提高到了 91.6%. 我们还放出了改进的 LSUN 和 ImageNet 来作为新的基准数据集.

我们发现学习鉴别分布内和分布外的样本表征是一个重要且未被充分探索的问题.我相信我们的工作将对未来的表征学习和 OOD 检测带来新的灵感和方向.

## 2. CSI:Contrasting shifted instances

待续….
