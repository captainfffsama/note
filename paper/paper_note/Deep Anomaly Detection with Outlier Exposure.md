#异常检测   

# Deep Anomaly Detection with Outlier Exposure
- 代码: https://github.com/hendrycks/outlier-exposure
- 文章: https://arxiv.org/abs/1812.04606
- 会议: ICLR 2019

## 摘要
识别异常的输入对于深度学习模型来说重要且困难,好在我们有大量且多样的数据可以用被用来作为辅助数据集,这种方法我们称为离群值暴露(Outlier Exposure,OE),这可以极大的增强异常检测器的性能并检测到未见过的异常.我们分析了 OE 的灵活性和鲁棒性,并总结了可以提高性能的数据集应有的特征.

## 1. 引言
深度神经网络分类器在对于不在训练样本分布中的异常测试样本倾向于给出高的预测置信度.   

过去一些工作尝试在分类器上设置一个异常分数来解决这个问题.这些分数可以被用来检测一些分布外样本(out of distribution,OOD).这些方法也已被证明对于复杂的输入空间也是有效的.这些方法不需要对完整的数据分布进行建模,而是使用启发式的放来来对未建模的对象进行预测.一些方法仅使用分布内的数据来对未建模的现象进行表征.  

本文将引入一种互补性的方法,我们通过学习输入数据是否是未建模的的提示来训练一个模型检测未建模数据.我们通过将模型暴露给 OOD 样本来学习到一个有效的启发式的方法来检测离群输入.

通过大量实验,我们证明了离群点暴露的有效性和泛用性.对于各种 CV 和 NLP 任务,离群点暴露 OE 也可以表现得很好.我们还证明了 OE 比现有的几种分布外数据检测的方法更好.此外,我们还证明了 OE 可以对 OOD 样本进行密度估计,这对 OOD 检测极为有用.

## 2. 相关工作
**神经网络分布外离群检测**  
Hendrycks & Gimpel(2017) 揭示了预训练模型比起分布内样本,分布外样本往往有更低的 softmax 置信度,所以分类器本身就可用来作为一个便利的分布外检测器.基于这个工作, DVries & Taylor (2018) 在预训练的分类器上添加了一个辅助分支,并从这个分支上得到一个新的 OOD 分数. Liang et al.(2018) 则介绍了一个方法,可以用来提高那些使用了 softmax distribution 的 OOD 检测器性能.它通过于输入数据使用对抗性扰动来进行预处理,使得异常和在分布内样本的 softmax 概率差异最大.

Lee et al.(2018) 结合 GAN 训练了一个分类器,该分类器在 GAN 样本上有更低的置信度.对于每个异常的测试分布,他们使用分布外的样本来微调分类器和 GAN. 与其不同,我们的方法不需要微调参数来适应特定域的异常测试分布,所以我们方法的结果和他们是没有可比性的. 很多工作都尝试鼓励模型在异常样本上有更低的置信度.最近, Liu et al.(2018)提供了一个理论证明,在异常检测器性能足够强的情况下,分布外的样本是可以被检测的.  

**利用辅助数据集**  
OE 使用一个和测试集完全不相关的辅助数据集来使得网络对异常检测有更好的表征. Goodfellow 通过在对抗性样本上训练来增加鲁棒性. Salakhutdinov 通过在网上图片上进行无监督学习来获得更加鲁棒的特征.后略.   

## 3. 离群暴露
我们将学习分布记作 $D_{in}$ ,来自 $D_{in}$ 的样本称为分布内样本.其余的样本可以称为 OOD,即分布外样本,或者说是来自 $D_{out}$ 的样本.在实际应用中,异常值的分布显然是难以提前指导的.给定一个参数化的 OOD 检测器和 OE 数据集 $D^{OE}_{out}$ ,和  $D^{test}_{out}$ 无关.我们尝试训练一个模型来发现和学习启发式的方法来检测一个样本是来自 $D_{in}$ 还是 $D^{OE}_{out}$ .我们发现学习到的启发式方法可以泛化到未见多的分布 $D_{out}$  

深度参数化的异常检测器可以从辅助数据集中学习到更好的表征.给定模型 $f$ 和原始学习目标 $L$ ,那么离群点暴露的公式即为最小化以下目标:

$$
E_{{(x,y)} \backsim D_{in}} [L(f(x),y)+ \lambda E_{x' \backsim D^{OE}_{out}} [L_{OE}(f(x'),f(x),y)]]
$$

由于标注好的数据不可得到,因此 $y$ 可以被忽略.  

由于 OE 可以应用在各种数据和原始任务上.所以 $L_{OE}$ 的具体形式取决于 OOD 检测器.比如,当使用最大化 softmax 概率的检测器 (Hendrycks & Gimpel,2017),我们可以将 $L_{OE}$ 设置为 $f(x')$ 和平均分布的交叉熵.当原始目标 $L$ 是密度估计且标签不可用时,我们设定 $L_{OE}$ 为 $f(x')$ 和 $f(x)$ 概率的log 的 [margin ranking loss](https://zhuanlan.zhihu.com/p/101143469).


## 4. 实验
我们在很多数据集上,在 OOD 检测器上进行来关于 OE 的消融实验.每组实验包括一个用于训练的分布类数据集 $D_{in}$ ,一个异常数据集 $D^{OE}_{out}$ ,一个基线 OOD 检测器.

在第一个试验中,我们展示了 OE 可以帮助检测器提升泛化.不同于以前的工作,本文工作在训练或者微调阶段,是不对测试数据分布进行访问的.在置信度分支的试验中,我们发现 OE 是可以作为一个二分的异常检测器.我们还证实了使用真实且多样的数据比使用合成的离群点数据更好.最后,我们在密度估计任务上进行了实验.我们发现边缘密度估计器倾向在分布外样本上分配更高的密度,我们使用 OE 则可以改善这个问题.  

### 4.1 在离群检测方法上的实验  
我们尝试评价分布外检测算法检测 OOD 点的性能.我们将 OOD 样本视为正, 使用 AUROC,AUPR, FPRN 作为评价指标.后略.

### 4.2 数据集
略

### 4.3 多分类
我们将多分类作为原始任务,我们使用 OE 来提升现存的 OOD 性能.在下面试验中,我们设定分类器的输入为 $x \in X$ ,类别标签为 $y \in y= \{ 1,2,...,k \}$ . 我们使用函数 $f: X \to R^k$ , 对于任意 $x$, $1^Tf(x) =1$和 $f(x) >= 0$ .

**最大化 Softmax 概率**  
考虑最大化 softmax 概率基线(Hendrychks & Gimpel,2017),它给出了输入 OOD 的分数-- $max_c f_c(x)$ . Out-of-distribution samples sre drawn from various unseen distributions (Appendix A). 对于每个任务,我们测试了比其它论文多2倍的  $D_{out}^{test}$ 数据,在 NLP 上我们也测试过了.评价 OOD 分数质量的方法描述见节 4.1. 对于多类的设置,我们使用预训练的分类器 $f$ 进行微调,这样它对 $D_{out}^{OE}$ 样本的后验更加均匀. 此时,微调的目标为 $E_{{(x,y)} \backsim D_{in}} [-log f_y(x)]+ \lambda E_{{x} \backsim D_{out}^{OE}} [H(U;f(x))]$ ,这里H是交叉熵,U是k类的平均分布.当类间不平衡,我们鼓励 $f(x)$ 和  $(P(y=1),...,P(y=k))$ 匹配;针对目前的数据集,我们让 $H$ 和 $U$ 匹配足够了.值得注意的是,从头训练 OE 甚至比使用微调更好.   

**译者注**   
实际[优化目标](https://github.com/hendrycks/outlier-exposure/blob/39e30940a81200f4d33ad2ade01a67ed4b9d7024/CIFAR/oe_tune.py#L174)为:
```python
# forward
x = net(data)

# backward
scheduler.step()
optimizer.zero_grad()

loss = F.cross_entropy(x[:len(in_set[0])], target)
# cross-entropy from softmax distribution to uniform distribution
loss += 0.5 * -(x[len(in_set[0]):].mean(1) - torch.logsumexp(x[len(in_set[0]):], dim=1)).mean()
```
这里关于 loss 的理解如下:   
交叉熵 $H$ 计算方式为:  

$$
H=- \sum_x p(x) log q(x)  \tag{1}
$$

这里 $p(x)$ 是平均分布,q(x) 是 softmax 分布,则上式为:

$$
\begin{align}
H&=- \sum_N \frac{1}{N} log \frac{e^{x_j}}{\sum^N_{i=1}e^{x_i}}  \\
&= -\frac{\sum_N log \frac{e^{x_j}}{\sum^N_{i=1}e^{x_i}} }{N}  \\
&= -\frac{\sum_N (log e^{x_j}-log{\sum^N_{i=1}e^{x_i}} )}{N}  \\
&= -( \frac{\sum^N x_j}{N}-\frac{\sum^Nlog{\sum^N_{i=1}e^{x_i}}}{N})  \\
&= -(E(x)-log{\sum^N_{i=1}e^{x_i}})
\end{align}
$$

对于每个分布 $D_{out}^{test}$ 我们不调整我们的超参数,所以 $D_{out}^{test}$ 是完全未知的.这里系数 $\lambda$ 是通过验证集 $D_{out}^{val}$ 确定的.在视觉任务中,我们使用 $\lambda =0.5$ 而在 NLP 中,使 $\lambda=1$,不同于以往 OOD 检测方法对网络进行微调,我们使用 $\lambda$ 对分类精度的影响是微乎其微的.

几乎所有的视觉任务,我们都对 WResNet 进行微调 10轮.对于 NLP,我们训练一个2层 GRU 5轮,然后带上 OE 微调2轮. CIFAR 系列数据集使用的离群暴露数据集是 Tiny Images, 而 Tiny ImageNet和 Place365 离群暴露数据集是 ImageNet-22K. NLP 离群暴露数据集是 WikiText-2.

**置信度分支**  
最近提出了一项 OOD 检测技术,将 OOD 分支 $b:X \to [0,1]$ 添加到深度网络.仅使用 $D_{in}$ 的样本分类,这个分支会估计输入的网络置信度.我们使用其公开代码训练了一个 40-4 Wide ResNet 分类网络.在网络原始优化目标上添上了 $0.5 E_{{x} \backsim D_{out}^{OE}} [logb(x)]$ .根据表3,可以看出置信度分支改善了 MSP 检测器,再添加了 OE 之后,置信度可以更加有效的检测异常了.

**人工合成离群点**  
OE 技术可以有效利用真实数据集的简单性,也可以用来生成合成离群点.我们对图片添加了噪声来生成离群点并将之作为离群点,但是分类器很快学会了这个模式,但其检测新的 OOD 的性能甚至没有之前的好.比较好的方法来自 Lee et al.(2018) ,他们在分类器的决策函数边界使用GAN来生成合成样本并将之用于训练,分类器被鼓励在这些合成样本上有较低的 maximum softmax probability.相比之下,我们从多样的数据集中挖掘异常样本的做法更加简单且足以用来提高 OOD 检测器性能.
