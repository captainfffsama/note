# DiffusionDrive: Truncated Diffusion Model for End-to-End Autonomous Driving
- 论文：[[2411.15139] DiffusionDrive: Truncated Diffusion Model for End-to-End Autonomous Driving](https://arxiv.org/abs/2411.15139)
- 代码：[hustvl/DiffusionDrive: [CVPR 2025 Highlight] Truncated Diffusion Model for Real-Time End-to-End Autonomous Driving](https://github.com/hustvl/DiffusionDrive)
- 会议： CVPR 2025

# 整体解析

### 1. 模型结构是怎样的？

根据论文图 4a (Overall pipeline) 和第 3.4 节的描述，DiffusionDrive 的整体模型结构主要由两个核心部分组成：

1.  **感知模块 (Perception Module)**：这个模块负责处理来自车载传感器（如摄像头和激光雷达）的原始数据，并将其转换为场景的中间表示。论文提到，DiffusionDrive 的设计是灵活的，可以集成多种现有的感知模块，例如 Transfuser [7]、UniAD [16] 或 VAD [20] 中使用的模块。在 NAVSIM 数据集的实验中，为了公平比较，作者采用了与 Transfuser [7] 相同的感知模块设置。这个模块的输出是后续规划模块所需的条件信息 `z`，通常包括鸟瞰图 (BEV) 特征、透视图 (PV) 特征、以及检测到的智能体 (agent) 和地图 (map) 的向量化查询。

2.  **扩散解码器 (Diffusion Decoder)**：这是 DiffusionDrive 的核心创新所在，它取代了传统方法中的确定性回归头（如 MLP）或基于词汇表的采样方法。该解码器接收感知模块提供的场景上下文信息，并以一组从“锚定高斯分布”中采样的带噪声的轨迹作为初始输入。然后，通过一个迭代的去噪过程，逐步将这些噪声轨迹优化为多样化且符合物理现实的驾驶轨迹。

整个流程可以概括为：传感器数据输入感知模块，生成场景表示；然后，这些场景表示作为条件，指导扩散解码器对一组初始噪声轨迹进行去噪，最终输出多条候选驾驶轨迹及其置信度分数。

### 2. 结构中每个模块的设计是怎样的？

#### 感知模块 (Perception Module)

如上所述，该模块是可插拔的。在论文的主要实验（NAVSIM 数据集）中，作者为了与 Transfuser [7] 对齐，采用了其设计：

*   **Backbone**: 使用 ResNet-34 [13] 作为图像特征提取的主干网络。
*   **输入**: 接收多个前视摄像头图像和光栅化的 BEV 激光雷达数据。
*   **输出**: 生成 BEV 特征图以及智能体（其他车辆、行人等）的查询向量。这些输出将作为条件信息 `z` 传递给扩散解码器。

#### 扩散解码器 (Diffusion Decoder)

这是论文的重点。根据图 4b 和第 3.4 节的详细描述，其内部结构设计如下：

*   **输入**:
    1.  一组带噪声的轨迹 `N_infer` (推理时) 或 `N_anchor` (训练时)。
    2.  来自感知模块的条件信息 `z`（BEV 特征、Agent/Map 查询等）。
    3.  当前的去噪时间步 `i`。

*   **核心层级结构 (Diffusion Decoder Layer)**: 解码器由多个相同的层堆叠而成（论文中提到堆叠了 2 层），并且这些层在去噪的多个时间步中是**参数共享**的。每一层的具体设计包括：
    1.  **空间交叉注意力 (Spatial Cross-Attention)**: 论文中提到了可变形注意力机制 (deformable attention)。轨迹上的每个点会根据其坐标，与 BEV 或 PV 特征图进行交互，从而让轨迹感知到周围的静态环境信息（如道路边界、车道线等）。
    2.  **智能体/地图交叉注意力 (Agent/Map Cross-Attention)**: 经过空间注意力增强后的轨迹特征，会进一步与感知模块提取的 Agent/Map 查询向量进行交叉注意力计算。这使得轨迹能够理解场景中的动态元素（如其他车辆的位置和意图）和高精地图信息。
    3.  **前馈网络 (Feed-Forward Network, FFN)**: 注意力计算之后，通过一个标准的前馈网络进行特征变换和提炼。
    4.  **时间步调制 (Timestep Modulation)**: 为了让网络知道当前处于去噪过程的哪个阶段，当前的时间步 `i` 会被编码并通过一个小的 MLP 网络，其输出会以仿射变换（相加或相乘）的方式融入到模型的中间层，从而调节网络的行为。
    5.  **输出头 (MLP Score/Traj.)**: 每一层处理完毕后，通过一个 MLP 头来预测两个输出：一个是**置信度分数 (Confidence Score)**，评估当前轨迹的质量；另一个是**轨迹坐标的偏移量**，用于对输入的噪声轨迹进行修正，使其更接近真实的轨迹。

*   **级联机制 (Cascade Mechanism)**: 论文中提到“recurs the cascade diffusion decoder to iteratively denoise the trajectory”。这意味着上一层解码器的输出会作为下一层解码器的输入，形成一种级联式的精炼过程。在推理时，这个解码器结构会被重复使用 `T_trunc` 次（例如 2 次），以完成整个迭代去噪过程。

### 3. 训练过程分几个阶段？每个阶段的输入输出，学习目标损失函数是什么?

根据论文第 4.2 节和附录 A 的描述，训练过程根据使用的数据集和基线有所不同：

*   **在 NAVSIM 数据集上**: 训练过程是**单阶段、端到端**的。模型从头开始在 `navtrain` 分割上进行训练。
*   **在 nuScenes 数据集上**: 作者遵循了 SparseDrive [39] 的**两阶段训练**方法。第一阶段预训练感知模块，第二阶段再接入并训练 DiffusionDrive 的规划模块。

这里我们主要详述论文核心贡献所在的**单阶段训练过程 (NAVSIM)**：

*   **输入 (Input)**:
    1.  **传感器数据**: 批量的摄像头图像和激光雷达 BEV 栅格图。
    2.  **真值轨迹 (Ground Truth Trajectory)**: `τ_gt`，即专家司机在对应场景下的驾驶轨迹。

*   **输出 (Output)**:
    模型 `f_θ` 接收 `N_anchor` 条加噪后的锚点轨迹和条件信息 `z` 后，会输出：
    1.  **预测的去噪轨迹**: `{ˆτ_k}`，共 `N_anchor` 条。
    2.  **预测的分类分数**: `{ˆs_k}`，共 `N_anchor` 条，代表每条轨迹是“好”轨迹的概率。

*   **学习目标损失函数 (Loss Function)**:
    训练的目标是让模型学会从加噪的锚点轨迹中恢复出真实的驾驶轨迹，并能准确判断哪条轨迹是最佳的。根据论文公式 (6)，总损失 `L` 由两部分组成：
    1.  **重构损失 (Reconstruction Loss, `L_rec`)**: 对于 `N_anchor` 个锚点，首先找到离真值轨迹 `τ_gt` 最近的那个锚点。以这个锚点为基础加噪生成的轨迹被视为**正样本** (`y_k = 1`)，其他的则为**负样本** (`y_k = 0`)。只对这个正样本计算其预测轨迹 `ˆτ_k` 和真值轨迹 `τ_gt` 之间的 `L1` 损失。
    2.  **分类损失 (Classification Loss, `BCE`)**: 对所有 `N_anchor` 条预测轨迹，都计算其预测分数 `ˆs_k` 和其标签 `y_k` (0 或 1) 之间的二元交叉熵 (Binary Cross-Entropy) 损失。

    总损失函数为：

    $$
    L = \sum_{k=1}^{N_{anchor}} [y_k L_{rec}(\hat{\tau}_k, \tau_{gt}) + \lambda BCE(\hat{s}_k, y_k)]
    $$

    其中 `λ` 是一个平衡两部分损失的超参数。

### 4. 训练数据具体的处理步骤是什么？

训练数据的处理是实现“截断扩散 (Truncated Diffusion)”策略的关键，主要步骤如下：

1.  **锚点轨迹聚类 (Anchor Clustering)**: 首先，在整个训练集的所有真值轨迹上运行 K-Means 聚类算法，得到 `N_anchor` 个聚类中心。这些中心轨迹 `{a_k}` 就构成了“锚点 (anchors)”，代表了数据集中最具代表性的几种驾驶模式（如直行、左转、右转、换道等）。论文中 `N_anchor` 设置为 20。

2.  **截断扩散加噪 (Truncated Diffusion Process)**: 在每个训练步骤中，不是从纯高斯噪声开始，而是从这些锚点轨迹 `{a_k}` 开始。根据公式 (4)，对每个锚点 `a_k` 添加**少量**的高斯噪声 `ϵ`。这个“少量”是通过**截断 (truncate)** 扩散时间表来实现的，即只执行完整扩散过程（例如 1000 步）的前 `T_trunc` 步（例如 50 步）。这样就生成了一组以锚点为中心、略带随机性的“锚定高斯分布 (anchored Gaussian distribution)”中的噪声轨迹 `{τ_i_k}`。

3.  **正负样本分配 (Positive/Negative Sample Assignment)**: 对于当前训练样本的真值轨迹 `τ_gt`，计算它与所有 `N_anchor` 个锚点 `a_k` 的距离，找到最近的那个锚点。从这个最近的锚点加噪生成的轨迹被标记为正样本 (`y_k=1`)，其余的全部标记为负样本 (`y_k=0`)。

4.  **传感器数据预处理**: 遵循 Transfuser 的设置，将三个前视摄像头图像进行裁剪和缩放，拼接成一个 1024x256 的图像。LiDAR 数据则被转换成光栅化的 BEV 图像。

### 5. 推理过程中输入输出又是什么？

*   **输入 (Input)**:
    1.  **实时传感器数据**: 当前时刻的摄像头图像和 LiDAR 点云。
    2.  **（内部生成）初始噪声轨迹**: 从“锚定高斯分布”中采样 `N_infer` 条初始噪声轨迹。`N_infer` 的数量可以根据计算资源和需求动态调整（例如 10, 20, 40），不一定等于训练时的 `N_anchor`。

*   **输出 (Output)**:
    模型会并行地对 `N_infer` 条初始轨迹进行去噪，最终生成 `N_infer` 条候选轨迹和它们各自的置信度分数。最终，选择**置信度分数最高的那一条轨迹**作为最终的规划结果输出。

### 6. 推理过程中数据是否有做特别处理？是如何做处理的？

是的，推理过程中的数据处理是该方法的核心优势之一，主要体现在以下两点：

1.  **从锚定高斯分布开始**: 与传统的扩散模型从纯随机高斯噪声 `N(0, I)` 开始不同，DiffusionDrive 的推理过程也是从**锚定高斯分布**开始的。具体做法是：取出预先计算好的 `N_anchor` 个锚点，对它们分别（或选择性地）添加少量噪声，生成 `N_infer` 条初始噪声轨迹。这个起点远比纯随机噪声更接近最终的合理轨迹，因此大大降低了去噪的难度。

2.  **截断去噪过程 (Truncated Denoising)**: 由于初始化的轨迹质量更高，模型不再需要漫长的迭代去噪过程。论文中指出，原本需要 20 步的 DDIM 扩散策略，现在**只需要 2 步**就可以生成高质量的轨迹。这极大地减少了计算开销，使得模型能够达到 45 FPS 的实时运行速度，满足了自动驾驶的实际应用需求。

总结来说，推理过程的“特别处理”就是**用一个更好的、包含先验知识的起点（锚定高斯分布），来替代随机起点，并因此能够大幅缩短生成过程（截断去噪）**，实现了速度和质量的双重提升。

# 一些细节
## 轨迹表示方式

根据论文第 3.1 节 “Preliminary” 中的 “Task formulation” 部分，一条轨迹的表示方法非常明确：

> The trajectory is represented as a sequence of waypoints **τ = {(x_t, y_t)}_t=1^T_f** , where T_f denotes the planning horizon, and (x_t, y_t) is the location of each waypoint at time t in the current ego-vehicle coordinate system.

一条轨迹在概念上就是一个点的列表，其形状就是 `[N_anchor, T_f, 2]` T_f 是规划时间域

## 论文训练是直接计算最终结果的 L1 损失

本文确实没有使用预测噪声的 L2 损失，而是直接使用了 L1 重建损失。 这两者是**替代关系**，而非并存关系。论文的总损失函数只包含 **L1 重建损失** 和 **BCE 分类损失** 两项。

下面我们来详细解释为什么会这样，以及这两种方法的区别。

### 1. 预测目标不同：预测最终轨迹 (x₀-prediction) vs. 预测噪声 (ϵ-prediction)

这是最根本的区别。

*   **标准扩散模型 (如 DDPM)**:
    *   **任务**: 模型被训练来预测在某一步 `t` 添加到干净数据 `x₀` 上的**噪声 `ϵ`**。
    *   **输入**: 带噪数据 `x_t` 和时间步 `t`。
    *   **输出**: 预测的噪声 `ϵ_θ(x_t, t)`。
    *   **损失函数**: `|| ϵ - ϵ_θ(x_t, t) ||²`，即真实噪声和预测噪声之间的 **L2 损失**。这种方法在从纯随机噪声生成复杂数据（如图像）时被证明非常稳定和有效。

*   **DiffusionDrive 模型**:
    *   **任务**: 模型被训练来直接预测**最终的、干净的轨迹 `τ_gt`** (在扩散模型术语里也叫 `x₀`)。
    *   **输入**: 带噪轨迹 `τ_i` 和时间步 `i`。
    *   **输出**: 预测的干净轨迹 `ˆτ` (论文中的 `ˆτ_k`)。
    *   **损失函数**: `L1(ˆτ, τ_gt)`，即预测的干净轨迹和真实轨迹之间的 **L1 重建损失**。

这两种方法在数学上是等价的，因为知道了 `x_t`, `t` 和 `ϵ`，就可以计算出 `x₀`；反之，知道了 `x_t`, `t` 和 `x₀`，也可以推算出 `ϵ`。然而，在实际训练中，直接预测 `x₀` 还是预测 `ϵ` 会对模型的学习动态产生影响。

**为什么 DiffusionDrive 选择直接预测最终轨迹 (`x₀`-prediction)？**

1.  **任务性质**: 自动驾驶的规划任务本质上是一个**回归 (Regression)** 任务，目标是得到一个精确的坐标序列。直接预测最终轨迹 `τ_gt` 的形式，与传统的规划模型（如直接用 MLP 回归轨迹）在目标上更为一致，这是一种非常自然的选择。

2.  **截断扩散的优势**: 由于 DiffusionDrive 采用的是“截断扩散”，其去噪过程的起点（带少量噪声的锚点）离终点（真实轨迹）**非常近**。在这种情况下，让模型直接“微调”出一个最终结果 (`x₀`-prediction)，可能比预测那个被加进去的、微小的随机噪声 (`ϵ`-prediction) 更加直接和高效。

### 2. 为何选择 L1 而不是 L2 重建损失？

当确定了要直接预测最终轨迹后，就面临着选择哪种重建损失的问题。L1 和 L2 都是回归任务中常用的损失函数。

*   **L2 损失 (均方误差, MSE)**: 对误差进行平方，因此对**异常值 (outliers)** 非常敏感。一个偏差很大的路点会产生巨大的损失值，可能主导梯度更新，导致模型为了迁就这个异常点而牺牲整体的平滑性。

*   **L1 损失 (平均绝对误差, MAE)**: 计算误差的绝对值，对所有误差一视同仁，对异常值的敏感度远低于 L2。在轨迹预测这类任务中，使用 L1 损失通常会产生**更平滑、更鲁棒 (robust)** 的结果，不容易被训练数据中个别的“奇怪”路点带偏。

因此，论文作者选择 L1 损失，是基于其在回归任务中（尤其是坐标预测）的鲁棒性优势，这在深度学习的实践中是一个相当普遍和成熟的选择。

### 总结

*   DiffusionDrive **没有** 使用预测噪声的 L2 损失。
* 它**替换**了传统的预测目标，不再预测噪声 `ϵ`，而是直接预测最终的干净轨迹 `τ_gt`。
* 基于这个新的预测目标，它采用了在轨迹回归任务中更鲁棒的 **L1 重建损失**。
* 总损失由这个 **L1 重建损失** (只对正样本计算) 和 **BCE 分类损失** (对所有样本计算) 共同构成，引导模型同时学习“如何生成好轨迹”和“如何评价轨迹好坏”。
## 论文设置细节

为了确保公平性，我们采用了与 Transfuser 相同的感知模块以及 ResNet-34 架构 [13]。在扩散解码器层中，我们遵循 Transfuser 的设计思路，仅使用基于 BEV（Bird’s-Eye View）的特征进行空间交叉注意力（spatial cross-attention）运算（这个是关键）。由于 Transfuser 的感知模块并未包含用于构建矢量化地图的功能，因此我们也仅执行代理（agent）级别的交叉注意力（agent cross-attention）运算。我们共堆叠了两个扩散解码器层，并采用了包含 20 个聚类锚点（clustered anchors）的扩散策略（diffusion policy）。在训练过程中，扩散算法的迭代次数被限制在 50 到 1000 次之间；而在推理阶段，我们仅执行两次去噪操作，并选择得分最高的预测轨迹作为评估结果。训练与推理的流程完全遵循 Transfuser 的设计规范：输入数据包括三张经过裁剪和缩放后的前置摄像头图像（每张图像的尺寸为 1024×256 像素），以及经过栅格化处理的 BEV 激光雷达数据。DiffusionDrive 模型的训练过程从零开始进行，使用了 AdamW 优化器，在 8 块 NVIDIA 4090 显卡上进行了 100 个训练周期，总批量大小为 512；学习率被设置为 1e-5。在测试阶段，我们没有对输入数据进行处理（即没有应用任何增强技术），最终评估结果为在 4 秒时间内生成的、包含 8 个关键点的轨迹数据。