#  Molmo and PixMo: Open Weights and Open Data for State-of-the-Art Multimodal Models 

#VLM #多模态 

# 引言

之前训练的多模态模型用的诸如 ShareGPT4V 等数据集本质上是使用 GPT-4V 生成的，仍然是专有 VLM 的提炼。

我们开放了 Molmo 系列的 VLM 模型和 PixMo 多模态数据集。

这个数据集的构建方式是要求标注员用语音描述图像 60 到 90 秒，而不是要求他们编写描述。我们提示标注员详细描述他们看到的每一件事，包括空间位置和关系的描述。

# 架构

架构包含四部分：

1. 预处理器：将输入图像转换成多尺度多 patch 的图像
2. ViT, 把图像转换成视觉 token， OpenAI 的 ViT-L/14 336px CLIP 模型（使用了高分辨率图像进行训练）
3. 一个连接器，将 token 转成 LLM 维度，然后对 token 进行池化减少其数量
4. 一个用于解码的 LLM，用了 OLMo-7B-1024，OLMoE-1B-7B，Qwen2-7B，Qwen2-72B
# 训练方式
## 一阶段：标题生成

ViT 和 LLM 使用固定权重，连接器使用随机初始化。使用 PixMo-Cap 训练模型进行标题生成。

### PixMo-Cap 的创建方式

首先根据 70 个高级主题（例如，街牌、梗图、食物、绘画、网站、模糊照片等）收集网络图片，并为每张图片要求三位标注员详细描述图片，至少讲述 60 秒（在收集的后期阶段，我们将时间增加到 90 秒，并使用每位标注员对每张图片进行标注；我们发现这样做效率更高，且质量没有下降）。标注员在描述时被提示回答一系列简单问题。

- 初看这幅图像是什么？
- 对象及其数量是什么？
- 文本说了什么？
- 物体的位置在哪里？
- 有哪些细微的细节是显而易见的？
- 背景中有什么？
- 风格和颜色是什么？
标注者的音频随后使用现成的语音转文字系统进行转录，然后使用仅语言型 LLM 处理转录文本以提高文本质量（例如，去除语音干扰，规范化风格）。我们还通过要求仅语言型 LLM 将三个原始转录本总结成一个描述，创建了第四个图像描述。  
我们的训练过程使用所有这四个图像 LLM 处理的转录本，当可用时，作为一种自然数据增强的形式。总共，我们在 712k 个独特的图像上进行了训练，包括 1.3M 个标题（包括增强）。

## 二阶段：监督微调

使用了几个学术数据集和新的 PixMo 系列的数据集来进行监督微调。

### PixMo-AskModelAnything

我们收集这些数据的目标是使模型能够回答各种各样的问题，涵盖用户在野外部署时可能会提出的问题。为了创建图像 - 问题 - 答案三元组，我们让标注者与一个仅语言 LLM 合作。首先，标注者会从大量图像中选择一张，然后为其编写一个问题。我们使用我们的第 1 阶段模型为图像生成密集的标题，并将该标题、图像的 OCR 输出（来自非 VLM 的现成 OCR 模型）和问题传递给一个仅语言 LLM。LLM 提供了一个答案（再次强调，它无法访问图像），标注者可以接受或拒绝这个答案。如果拒绝，他们会描述答案有什么问题，并要求 LLM 修正。标注者会重复这个过程，直到答案令人满意。对于一些数据，我们要求标注者根据特定的提示提出问题，包括一些不寻常的要求，例如要求将答案写成颠倒的（这是使用 Unicode 可以做到的）。这个数据集包含 162k 个问题 - 答案对和 73k 张图像。

### PixMo-Points

我们收集了实现三个目标的指向数据：（1）使模型能够指向文本描述的任何事物，（2）使模型能够通过指向进行计数，（3）使模型能够在回答问题时将指向作为一种自然形式的视觉解释。为了收集实现前两个目标的数据，我们要求人工标注员在图像中指向某个事物，并描述它，然后指向图像中该事物的每个实例（使指向全面）。我们还收集了“不存在”数据，以便模型能够学习在询问图像中不存在的事物时做出适当的响应。这些数据还自然地使我们能够训练模型通过将指向作为思维链的形式来回答计数问题。我们从 428,000 张图像中收集了 2,300,000 个问题 - 指向对。为了使指向成为一种解释形式，我们遵循了 PixMo-AskModelAnything 流程，但对其进行了增强，以便标注员可以向 LLM 传递一个包含文本标注点的列表。然后，LLM 被提示如果适当，则使用这些点来支持其答案。我们从 29,000 张图像中收集了 79,000 个问题 - 答案对。

### PixMo-CapQA

我们从 165k 张图片中通过提示仅使用图像的 ground-truth 标题来提问和回答问题的语言 LLM，生成了额外的 214k 个问答对。为了增加多样性，我们创建了一个高级主题和风格列表，并要求模型使用这些内容。

### PixMo-Docs

我们提示 LLM 为 255k 个文本和图表密集型图像生成代码，包括图表、文档、表格和图表。然后，我们提示 LLM 基于对代码的特权访问生成 2.3M 个问答对（图像未使用）

### PixMo-Clocks

我们构建了一个包含关于时间的问题和答案的新合成模拟时钟数据集。图像是从 50 种不同的手表和 160k 种多样化的真实手表面风格中渲染出来的，这些风格具有随机选择的时间。我们收集了 826k 个示例。