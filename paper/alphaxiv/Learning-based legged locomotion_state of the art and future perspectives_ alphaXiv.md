#具身智能 #综述 #强化学习 #alphaXiv 

[toc]

# 引言

腿足式移动是机器人领域最具挑战性和雄心壮志的前沿之一，它有望在复杂、非结构化的环境中实现普遍的移动能力。尽管传统的基于模型的控制方法在几十年里一直主导着该领域，但近年来，基于学习的方法，特别是深度强化学习（DRL），取得了爆炸性进展。这篇全面的综述综合了基于学习的腿足式移动的当前状态，审视了先进硬件、高保真模拟和复杂算法的融合，正是这种融合彻底改变了腿足机器人所能达到的成就。

![](https://paper-assets.alphaxiv.org/figures/2406.01152v2/img-0.jpeg)

_图 1：通过基于学习的方法实现的先进移动技能示例，展示了机器人在复杂地形中导航、操纵物体和执行动态机动。_

自 Marc Raibert 在 20 世纪 80 年代开创性工作以来，该领域取得了显著发展，基于学习的方法现在使机器人能够掌握跑酷、穿越挑战性地形并在行走时执行操作任务。这种转变源于三项关键技术进步：开发了具有本体感觉执行器的鲁棒硬件平台、出现了能够生成大量训练数据的 GPU 加速物理模拟器，以及适用于连续控制问题的深度学习算法的成熟。

# 历史演变与技术融合

基于学习的腿足式移动的发展历程以不同的技术发展阶段为标志。早期的努力主要依赖于手工设计的控制器和简单的启发式方法，受限于计算和硬件能力。2000 年代引入更复杂的基于模型的方法，包括模型预测控制（MPC）和全身控制（WBC）等方法，提供了理论基础，但在实际世界的鲁棒性和适应性方面面临挑战。

![](https://paper-assets.alphaxiv.org/figures/2406.01152v2/img-1.jpeg)

_图 2：2000 年至 2024 年腿足机器人硬件的演变，展示了从早期研究原型到现代商业平台的进展。_

突破性的进展源于三个关键促成因素的融合：

**硬件演变**：现代腿足机器人具有本体感觉执行器，提供高带宽的力/扭矩控制，内置柔顺性和抗冲击性。麻省理工学院猎豹系列、波士顿动力机器人以及优必选等经济实惠的商业平台使更多人能够接触到有能力的硬件。

**模拟器进步**：Isaac Gym、MuJoCo XLA 等 GPU 加速物理引擎现在可以并行模拟数千个机器人，为深度学习生成海量数据集，同时保持足够的保真度以实现从模拟到现实的迁移。

**算法成熟**：深度强化学习算法，特别是像近端策略优化（PPO）这样的在线策略方法，已被证明在学习高维连续动作空间中的复杂移动行为方面非常有效。

# 理论基础与学习范式

基于学习的移动本质上是将机器人控制视为马尔可夫决策过程（MDP），其中机器人必须通过与环境的互动学习将感官观察映射到运动指令。这种公式化方法使得强化学习的应用成为可能，智能体通过试错，在奖励信号的指导下学习最优行为。

![](https://paper-assets.alphaxiv.org/figures/2406.01152v2/img-2.jpeg)

_图 3：常用于腿足运动的机器学习算法的分层分类法，展示了不同方法之间的关系。_

该领域采用三种主要的学习范式：

**深度强化学习**：主流方法，通过与环境交互来训练策略。像 PPO 这样的在策略方法已被证明特别有效，因为它们具有稳定的学习动态和对超参数选择的鲁棒性。典型的公式涉及学习一个将观测映射到动作的神经网络策略π(a|s)，以最大化预期的累积奖励为目标进行优化。

**模仿学习**：一种替代方法，从专家演示而不是环境奖励中学习。行为克隆直接从演示数据中监督策略学习，而更复杂的方法（如生成对抗模仿学习（GAIL））可以从未标记的运动数据中学习。

**混合方法**：日益流行的方法，将学习与基于模型的控制相结合，利用两种范式的优势以实现卓越的性能、样本效率和鲁棒性。

# 腿足运动的 MDP 公式

基于学习的方法的成功关键在于 MDP 组件的仔细制定。这涉及对状态表示、动作空间和奖励设计做出周全的选择，以实现有效的学习，同时确保现实世界的迁移性。

**状态表示**：现代方法通常采用丰富的本体感受信息，包括关节位置、速度、身体姿态和接触状态。许多成功的实现会维护历史缓冲区以捕获时间依赖性。对于导航任务，来自摄像头或激光雷达的外部感受信息通常通过学习表示或深度图像进行编码。

**动作空间**：动作空间的选择显著影响学习效率和策略可解释性。低级方法直接输出关节位置或扭矩，而结构化动作空间可以参数化更高级别的运动基元或提供对名义控制器的修正。

**奖励设计**：有效的奖励函数通常结合任务目标（速度跟踪、导航目标）与正则化项，以鼓励自然的步态、能源效率和安全行为。设计过程通常涉及迭代细化，以平衡不同目标并防止不必要的行为。

# 学习框架和训练方法

已经出现了几种用于训练运动策略的总体框架，每种都解决了学习挑战的不同方面。

![](https://paper-assets.alphaxiv.org/figures/2406.01152v2/img-4.jpeg)

_图 4：用于运动的不同学习框架：(a) 基本强化学习公式，(b) 带有渐进任务的课程学习，(c) 带有技能分解的分层学习，和 (d) 带有教师 - 学生架构的特权学习。_

**课程学习**：逐渐增加任务难度或环境复杂性以引导学习进程。这可能包括从平坦地形开始，逐步引入障碍物，或从简单步态开始，进而发展到更复杂的行为。

**分层学习**：将复杂的运动任务分解为高级规划和低级技能执行。高级策略可能选择落脚点位置或步态参数，而低级控制器则处理详细的电机控制。

**特权学习**：一种特别有效的方法，它在模拟中训练一个可访问特权信息（完美状态估计、真实地形图）的“教师”策略，然后将这些知识提炼成一个使用现实传感器限制运行的“学生”策略。该框架通过隐式学习状态估计和环境适应，巧妙地解决了从模拟到现实的差距。

# 弥合模拟到现实的差距

在基于学习的运动控制中，最具挑战性的问题之一是将模拟中训练的策略转移到真实世界的硬件上。模拟到现实的差距源于建模不准确、未建模的动力学、传感器噪声以及难以在模拟中完美捕捉的环境变化。

![](https://paper-assets.alphaxiv.org/figures/2406.01152v2/img-5.jpeg)

_图 5：用于模拟到现实转移的域适应方法概述，展示了不同训练算法、策略条件机制和适应模块的集成。_

以下几种策略已被证明能有效应对这一挑战：

**领域随机化**：在训练期间随机化物理参数、环境条件和传感器特性，以提高策略的鲁棒性。这包括改变机器人质量、摩擦系数、执行器增益、地形特性，并向观测中添加噪声。

**系统辨识**：通过从真实机器人数据中学习精确的执行器动力学、接触力学和传感器特性模型，提高模拟器保真度。这可以涉及拟合参数模型或学习神经网络校正名义模拟模型。

**适应机制**：使策略能够通过在线学习或显式参数识别自动适应真实世界条件。这可能涉及学习环境条件的潜在表示或维护指导探索的不确定性估计。

**设计原则**：在奖励设计、观测空间和动作表示方面做出审慎选择，以促进与真实世界约束和传感器限制兼容的行为。

# 仿真环境及其影响

物理仿真的质量和效率一直是基于学习的运动控制的关键推动因素。现代仿真器已经发展到既提供高保真度又提供计算效率，通常利用 GPU 加速来并行训练数千个机器人。

![](https://paper-assets.alphaxiv.org/figures/2406.01152v2/img-3.jpeg)

_图 6：过去六年中，不同物理模拟器在学习运动控制方面的使用增长，显示了 Isaac Gym 的显著崛起和 MuJoCo 的持续流行。_

主要发展包括：

*   **GPU 加速物理**：Isaac Gym 等模拟器可以并行模拟数千个环境，将训练时间从几天大幅缩短到几小时。
*   **可微分仿真**：新兴的模拟器提供通过物理仿真的梯度，从而实现更高效的样本学习和系统辨识。
*   **接触建模**：改进了接触动力学、摩擦和冲击模型，更好地捕捉机器人与环境之间复杂的相互作用。

# 混合控制 - 学习方法

成功的最新方法并非将学习和基于模型的控制视为竞争范式，而是将两种方法集成起来，以利用它们的互补优势。这些混合框架可分为以下几种类型：

**学习增强型模型控制**：利用学习来通过学习更好的模型、调整参数或提供前馈指令来提高传统控制器的性能。例如，为 MPC 控制器学习特定地形的接触模型或最优落脚点选择。

**模型引导学习**：通过演示数据、热启动策略或限制行动空间，将基于模型的洞察融入学习过程。基于模型的控制器可以提供安全的初始策略或生成多样化的训练数据。

**分层集成**：将高层基于学习的规划与低层基于模型的控制相结合，或反之，使用基于模型的规划与学习到的低层技能。

这些混合方法通常比纯粹基于学习或基于模型的方法实现更优越的性能，提供了更高的样本效率、鲁棒性和可解释性。

# 扩展到双足和人形系统

继四足运动取得成功之后，基于学习的方法正越来越多地应用于双足和人形机器人。这代表了一个重大转变，因为双足运动带来了独特的挑战，包括更高维度的动力学、更小的稳定性裕度以及更复杂的接触模式。

双足学习的最新成就包括在崎岖地形上的动态行走和跑步、跳跃和攀爬等跑酷技能，甚至杂技动作。驱动四足机器人成功的相同技术促成因素——本体感受执行器、高效仿真和鲁棒学习算法——现在正使人形机器人的运动能力变得越来越可行。

有能力的人形机器人具有特别引人注目的潜在应用，因为它们可以在人类设计的环境中运行而无需修改。这导致了对人形机器人开发的新一轮商业兴趣和重大投资。

# 未来方向和开放挑战

几个关键的研究前沿将塑造下一代基于学习的腿式运动：

**无监督技能发现**：通过使机器人能够自主发现多样化、可重用的技能来减少奖励工程的负担，这些技能随后可以组合用于特定任务。

**鲁棒性和安全性**：开发提供正式安全保证的方法，同时保持基于学习方法的适应性和性能。这包括学习过程中的安全探索和部署的认证鲁棒策略。

**运动操作**：将复杂的物体操作与动态运动相结合，以创建真正多功能的移动机器人，能够与环境互动。

**基础模型**：探索大规模预训练模型如何通过更好的场景理解、常识推理或跨任务和形态的知识迁移来增强机器人能力。

**环境适应**：超越现有方法，处理极端环境、可变重力或可能用于太空探索或灾难响应的新型运动模式。

# 社会影响和伦理考量

基于学习的腿式运动的快速发展引发了关于能力日益增强的机器人对社会影响的重要问题。这篇综述强调了积极应对这些挑战的必要性：

**武器化担忧**：作者明确谴责开发致命自主武器系统，并支持国际上禁止此类武器的呼吁，认识到先进机器人能力的双重用途性质。

**经济影响**：认识到有能力的腿式机器人可能会取代某些工作，该论文倡导深思熟虑的政策制定，并强调人机协作而非替代。

**环境影响**：提高对大规模人工智能训练碳足迹的认识，以及对机器人开发和部署采取可持续方法的必要性。

这份全面的概述表明，基于学习的足式移动已从学术好奇心发展成为具有变革性潜力的实用技术。硬件、仿真和算法进步的融合实现了前所未有的能力，同时开辟了新的研究前沿，这将塑造机器人技术和人机交互的未来。
